{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enclosed-violation",
   "metadata": {},
   "source": [
    "# Benchmarking the application \"Downscaling of 2m temperature from IFS HRES with a U-Net\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-audience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handy-basic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas==1.1.\n",
    "!pip install tensorflow==2.3.1\n",
    "!pip install climetlab==0.8.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-stewart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: climetlab-maelstrom-downscaling==0.1.0 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (0.1.0)\n",
      "Requirement already satisfied: climetlab>=0.8.14 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab-maelstrom-downscaling==0.1.0) (0.8.14)\n",
      "Requirement already satisfied: cdsapi in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: pyodc in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: eccodes>=0.9.9 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: magics>=1.5.6 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.5.7)\n",
      "Requirement already satisfied: pandas in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (6.0)\n",
      "Requirement already satisfied: entrypoints in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.3)\n",
      "Requirement already satisfied: pdbufr in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: dask in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2022.1.0)\n",
      "Requirement already satisfied: tqdm in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (4.46.1)\n",
      "Requirement already satisfied: ecmwflibs>=0.1.2 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.4.3)\n",
      "Requirement already satisfied: xarray>=0.18.2 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.20.2)\n",
      "Requirement already satisfied: cfgrib>=0.9.8.4 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.9.9.1)\n",
      "Requirement already satisfied: numpy in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.18.5)\n",
      "Requirement already satisfied: requests in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.23.0)\n",
      "Requirement already satisfied: toolz in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.11.2)\n",
      "Requirement already satisfied: branca==0.3.1 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: ecmwf-api-client>=1.6.1 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: markdown in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (3.3.6)\n",
      "Requirement already satisfied: psutil in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (5.9.0)\n",
      "Requirement already satisfied: folium>=0.12.1 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.12.1.post1)\n",
      "Requirement already satisfied: netcdf4 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.5.1.2)\n",
      "Requirement already satisfied: cffi in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from pyodc->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: findlibs in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from eccodes>=0.9.9->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.0.2)\n",
      "Requirement already satisfied: attrs in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from eccodes>=0.9.9->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (21.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from pandas->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from pandas->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2020.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (20.4)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2022.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7; python_version < \"3.8\" in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from xarray>=0.18.2->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (4.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from xarray>=0.18.2->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (4.10.1)\n",
      "Requirement already satisfied: click in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from cfgrib>=0.9.8.4->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (8.0.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from requests->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from requests->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from requests->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from requests->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (3.0.4)\n",
      "Requirement already satisfied: six in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from branca==0.3.1->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from branca==0.3.1->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (3.0.3)\n",
      "Requirement already satisfied: cftime in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from netcdf4->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: pycparser in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from cffi->pyodc->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.20)\n",
      "Requirement already satisfied: locket in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from partd>=0.3.10->dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (0.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /srv/conda3/envs/py3-agb/lib/python3.7/site-packages (from packaging>=20.0->dask->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->xarray>=0.18.2->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /automount/user/s6mllang/.local/lib/python3.7/site-packages (from jinja2->branca==0.3.1->climetlab>=0.8.14->climetlab-maelstrom-downscaling==0.1.0) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install climetlab-maelstrom-downscaling==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wired-hydrogen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/user/s6mllang/.local/bin/\")\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.utils as ku\n",
    "from downscaling_utils import *\n",
    "from unet_model import build_unet, get_lr_scheduler\n",
    "import xarray as xr\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-headline",
   "metadata": {},
   "source": [
    "... we define to auxiliary functions that accomplish this job for us. Note that the function `get_ifs_data`automatically detects the running node to decide if data can be downloaded or if it must be available on scratch. If the data is unavailable in the file system, execution on the login node to acquire the data is **mandatory**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-mercy",
   "metadata": {},
   "source": [
    "Now, let's get the data. For this, please **adapt the `datadir`-variable** if you don't have access to `/p/project/deepacf/maelstrom/data/downscaling_unet/` (check via terminal). In this case, also run on the **login node first** to download the data. If you have access (or if you already obtained the data), the data will be loaded from the filesystem automatically (also on the computing node). <br>\n",
    "For convenience, we will also take a brief look on the training data which comprises 1464 time steps over our target domain with 128x96 grid points in zonal and meridional direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daily-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%set_download_flag: Datafiles are already available under '/automount/user/s6mllang/fzj_esde/maelstrom/downscaling_data'\n",
      "%get_data: Start reading the data from '/automount/user/s6mllang/fzj_esde/maelstrom/downscaling_data'...\n",
      "%get_data: Dataset was retrieved succesfully.\n"
     ]
    }
   ],
   "source": [
    "datadir = \"/automount/user/s6mllang/fzj_esde/maelstrom/downscaling_data\"\n",
    "\n",
    "data_obj = DownscalingData(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "russian-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loading': 4.351184751838446, 'preprocessing_train': 0.5186087638139725, 'preprocessing_val': 0.05851025879383087}\n",
      "{'train': 575681728, 'val': 73141456, 'test': 70782112}\n",
      "{'train': 1464, 'val': 186, 'test': 180}\n"
     ]
    }
   ],
   "source": [
    "# set daytime for which downsclaing model is trained (i.e. either 0 or 12)\n",
    "hour = 12    \n",
    "\n",
    "# preprocess data for training\n",
    "int_data, tart_data, opt_norm = data_obj.preprocess_data(\"train\", daytime=12)\n",
    "inv_data, tarv_data = data_obj.preprocess_data(\"val\", daytime=hour, opt_norm=opt_norm)\n",
    "\n",
    "print(data_obj.timing)\n",
    "print(data_obj.data_info[\"memory_datasets\"])\n",
    "print(data_obj.data_info[\"nsamples\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informal-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as ku\n",
    "shape_in = (96, 128, 3)\n",
    "\n",
    "if \"login\" in data_obj.host:\n",
    "    unet_model = build_unet(shape_in, z_branch=True)\n",
    "    ku.plot_model(unet_model, to_file=os.path.join(os.getcwd(), \"unet_downscaling_model.png\"), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assisted-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class for creating timer callback\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.epoch_times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "z_branch = True                    # flag if additionally training on surface elevation is performed\n",
    "\n",
    "# create callbacks\n",
    "callback_list = [get_lr_scheduler(), TimeHistory()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23/23 [==============================] - 731s 32s/step - loss: 0.6786 - output_temp_loss: 0.2998 - output_z_loss: 0.3788 - val_loss: 9.4799 - val_output_temp_loss: 3.3630 - val_output_z_loss: 6.1168\n",
      "Epoch 2/2\n",
      " 2/23 [=>............................] - ETA: 5:31 - loss: 0.3606 - output_temp_loss: 0.2260 - output_z_loss: 0.1346"
     ]
    }
   ],
   "source": [
    "# build, compile and train the model\n",
    "nepochs = 2\n",
    "unet_model = build_unet(shape_in, z_branch=z_branch)\n",
    "if z_branch:\n",
    "    unet_model.compile(optimizer=Adam(learning_rate=5*10**(-4)),\n",
    "                   loss={\"output_temp\": \"mae\", \"output_z\": \"mae\"}, \n",
    "                   loss_weights={\"output_temp\": 1.0, \"output_z\": 1.0})\n",
    "    \n",
    "    history = unet_model.fit(x=int_data.values, y={\"output_temp\": tart_data.isel(variable=0).values,\n",
    "                                                   \"output_z\": tart_data.isel(variable=1).values},\n",
    "                             batch_size=32, epochs=nepochs, callbacks=callback_list, \n",
    "                             validation_data=(inv_data.values, {\"output_temp\": tarv_data.isel(variable=0).values,\n",
    "                                                                \"output_z\": tarv_data.isel(variable=1).values}))\n",
    "else:\n",
    "    unet_model.compile(optimizer=Adam(learning_rate=5*10**(-4)), loss=\"mae\")\n",
    "\n",
    "    history = unet_model.fit(x=int_data.values, y=tart_data.isel(variable=0).values, batch_size=32,\n",
    "                             epochs=nepochs, callbacks=callback_list,\n",
    "                             validation_data=(inv_data.values, tarv_data.isel(variable=0).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test data first\n",
    "inte_data, tarte_data = preprocess_data_for_unet(ds_test, daytime=hour, opt_norm=opt_norm)\n",
    "\n",
    "# generate the downscaled fields\n",
    "y_pred_test = unet_model.predict(inte_data.values, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_type = \"test\"            # change here to switch between validation and testing data\n",
    "if comparison_type == \"validation\":\n",
    "  y_pred = y_pred_val\n",
    "  ds_ref = ds_val.sel(time=dt.time(hour))\n",
    "  var_ref = tarv_data.isel(variable=0)\n",
    "elif comparison_type == \"test\":\n",
    "  y_pred = y_pred_test\n",
    "  ds_ref = ds_test.sel(time=dt.time(hour))\n",
    "  var_ref = tarte_data.isel(variable=0)\n",
    "else:\n",
    "  ValueError(\"Unknown comparison_type '{0}' chosen.\".format(comparison_type))\n",
    "\n",
    "if np.ndim(y_pred) == 5:                # cropping necessary if z_branch is True (two output channels)\n",
    "  y_pred = y_pred[0]\n",
    "else:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some relevant information from the original dataset, ...\n",
    "coords = var_ref.squeeze().coords\n",
    "dims = var_ref.squeeze().dims\n",
    "\n",
    "# denomralize...\n",
    "y_pred_trans = np.squeeze(y_pred)*opt_norm[\"std_tar\"].squeeze().values + opt_norm[\"mu_tar\"].squeeze().values\n",
    "# and make xarray DataArray \n",
    "y_pred_trans = xr.DataArray(y_pred_trans, coords=coords, dims=dims, name=\"t2m_downscaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((y_pred_trans - ds_ref[\"t2m_tar\"])**2).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "print(\"MSE of downscaled 2m temperature: {0:.3f} K**2 (+/-{1:.3f} K**2)\".format(mse.mean().values, mse.std().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-stack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alpha-pilot",
   "metadata": {},
   "source": [
    "As we see, the model has learned to recover a lot of details resulting mainly from the topography. Especially over the Alpes, but also over the the German low mountain ranges, the differences have become smaller and less structured. It is also noted that the differences near the coast (e.g. at the Baltic Sea) have become smaller. <br>\n",
    "However, some systematic features are still visible, the differences can stilll be as large as 3 K and especially in the Alps, the differences are somehow 'blurry'. Thus, there is still room for further improvement. \n",
    "These improvements will not only pertain the model architecture, but will also target to engulf more meteorological variables. The latter will also enable the network to generalize with respect to daytime and season. Note, that this has not been done yet, since we trained the U-net with data between April and September at 12 UTC only.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-agb [conda env:py3-agb]",
   "language": "python",
   "name": "conda-env-py3-agb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
