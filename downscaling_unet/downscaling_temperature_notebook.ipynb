{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unique-watson",
   "metadata": {},
   "source": [
    "# Downscaling of 2m temperature with a U-Net\n",
    "\n",
    "The following U-net architecture is adopted from Sha et. al, 2020 and applied to downscale ERA5 reanalysis data at coarse resolution (dx=0.8Â°) to the higher resolved IFS HRES forecast grid.\n",
    "First, let's import all the Python-modules we need to build the U-net based downscaling network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outside-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# import tensorflow and required stuff from Keras API\n",
    "import tensorflow as tf\n",
    "\n",
    "# all the layers used for U-net\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D\n",
    ")\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-century",
   "metadata": {},
   "source": [
    "We continue by creating the building blocks of the U-net architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impaired-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters: int, kernel: tuple = (3,3), padding: str = \"same\",\n",
    "               activation: str = \"relu\", kernel_init: str = \"he_normal\", l_batch_normalization: bool = True):\n",
    "    \"\"\"\n",
    "    A convolutional layer with optional batch normalization\n",
    "    :param inputs: the input data with dimensions nx, ny and nc\n",
    "    :param num_filters: number of filters (output channel dimension)\n",
    "    :param kernel: tuple indictating kernel size\n",
    "    :param padding: technique for padding (e.g. \"same\" or \"valid\")\n",
    "    :param activation: activation fuction for neurons (e.g. \"relu\")\n",
    "    :param kernel_init: initialization technique (e.g. \"he_normal\" or \"glorot_uniform\")\n",
    "    \"\"\"\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)\n",
    "    if l_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding=\"same\", activation=\"relu\", \n",
    "                     kernel_init=\"he_normal\", l_batch_normalization=True):\n",
    "    \"\"\"\n",
    "    Sequential application of two convolutional layers (using conv_block).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = conv_block(inputs, num_filters, kernel, padding, activation,\n",
    "                   kernel_init, l_batch_normalization)\n",
    "    for i in np.arange(n-1):\n",
    "        x = conv_block(x, num_filters, kernel, padding, activation,\n",
    "                       kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters, kernel_maxpool: tuple=(2,2), l_large: bool=True):\n",
    "    \n",
    "    if l_large:\n",
    "        x = conv_block_n(inputs, num_filters, n=2)\n",
    "    else:\n",
    "        x = conv_block(inputs, num_filters)\n",
    "        \n",
    "    p = MaxPool2D(kernel_maxpool)(x)\n",
    "    \n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= \"same\", \n",
    "                  activation=\"relu\", kernel_init=\"he_normal\", l_batch_normalization: bool=True):\n",
    "    \n",
    "    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-pierre",
   "metadata": {},
   "source": [
    "With the building blocks at hand, we finally build the U-net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape, channels_start=56):\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\" encoder \"\"\"\n",
    "    s1, e1 = encoder_block(inputs, channels_start, l_large=True)\n",
    "    s2, e2 = encoder_block(e1, channels_start*2, l_large=False)\n",
    "    s3, e3 = encoder_block(e2, channels_start*4, l_large=False)\n",
    "    \n",
    "    \"\"\" bridge encoder <-> decoder \"\"\"\n",
    "    b1 = conv_block(e3, channels_start*8)\n",
    "    \n",
    "    \"\"\" decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, channels_start*4)\n",
    "    d2 = decoder_block(d1, s2, channels_start*2)\n",
    "    d3 = decoder_block(d2, s1, channels_start)\n",
    "    \n",
    "    outputs = conv_block(d3, 1)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"Temp U-Net\")\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Temp U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 96, 2)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 96, 56)  1064        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 96, 56)  224         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 96, 56)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 96, 56)  28280       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 96, 56)  224         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 96, 56)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 48, 56)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 48, 112)  56560       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 48, 112)  448         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 48, 112)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 24, 112)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 24, 224)  226016      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 24, 224)  896         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 24, 224)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 12, 224)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 12, 448)  903616      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 12, 448)  1792        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 12, 448)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 24, 224)  401632      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 24, 448)  0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 24, 224)  903392      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 24, 224)  896         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 24, 224)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 24, 224)  451808      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 24, 224)  896         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 24, 224)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 48, 112)  100464      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 48, 224)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 48, 112)  225904      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 48, 112)  448         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 48, 112)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 48, 112)  113008      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 48, 112)  448         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 48, 112)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 96, 56)  25144       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 96, 112) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 96, 56)  56504       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 96, 56)  224         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 96, 56)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 96, 56)  28280       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 96, 56)  224         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 96, 56)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 96, 1)   505         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 96, 1)   4           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 96, 1)   0           batch_normalization_11[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,528,901\n",
      "Trainable params: 3,525,539\n",
      "Non-trainable params: 3,362\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(128, 96, 2)\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.0",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
