{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mathematical-summit",
   "metadata": {},
   "source": [
    "# Downscaling of 2m temperature with a U-Net\n",
    "\n",
    "The following U-net architecture is adopted from Sha et. al, 2020 and applied to downscale ERA5 reanalysis data at coarse resolution (dx=0.8Â°) to the higher resolved IFS HRES forecast grid.\n",
    "First, let's import all the Python-modules we need to build the U-net based downscaling network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "charming-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import datetime as dt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# import tensorflow and required stuff from Keras API\n",
    "import tensorflow as tf\n",
    "\n",
    "# all the layers used for U-net\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D\n",
    ")\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-bookmark",
   "metadata": {},
   "source": [
    "We continue by creating the building blocks of the U-net architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "allied-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters: int, kernel: tuple = (3,3), padding: str = \"same\",\n",
    "               activation: str = \"relu\", kernel_init: str = \"he_normal\", l_batch_normalization: bool = True):\n",
    "    \"\"\"\n",
    "    A convolutional layer with optional batch normalization\n",
    "    :param inputs: the input data with dimensions nx, ny and nc\n",
    "    :param num_filters: number of filters (output channel dimension)\n",
    "    :param kernel: tuple indictating kernel size\n",
    "    :param padding: technique for padding (e.g. \"same\" or \"valid\")\n",
    "    :param activation: activation fuction for neurons (e.g. \"relu\")\n",
    "    :param kernel_init: initialization technique (e.g. \"he_normal\" or \"glorot_uniform\")\n",
    "    \"\"\"\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)\n",
    "    if l_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding=\"same\", activation=\"relu\", \n",
    "                     kernel_init=\"he_normal\", l_batch_normalization=True):\n",
    "    \"\"\"\n",
    "    Sequential application of two convolutional layers (using conv_block).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = conv_block(inputs, num_filters, kernel, padding, activation,\n",
    "                   kernel_init, l_batch_normalization)\n",
    "    for i in np.arange(n-1):\n",
    "        x = conv_block(x, num_filters, kernel, padding, activation,\n",
    "                       kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters, kernel_maxpool: tuple=(2,2), l_large: bool=True):\n",
    "    \n",
    "    if l_large:\n",
    "        x = conv_block_n(inputs, num_filters, n=2)\n",
    "    else:\n",
    "        x = conv_block(inputs, num_filters)\n",
    "        \n",
    "    p = MaxPool2D(kernel_maxpool)(x)\n",
    "    \n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= \"same\", \n",
    "                  activation=\"relu\", kernel_init=\"he_normal\", l_batch_normalization: bool=True):\n",
    "    \n",
    "    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-strategy",
   "metadata": {},
   "source": [
    "With the building blocks at hand, we finally build the U-net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expected-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape, channels_start=56):\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\" encoder \"\"\"\n",
    "    s1, e1 = encoder_block(inputs, channels_start, l_large=True)\n",
    "    s2, e2 = encoder_block(e1, channels_start*2, l_large=False)\n",
    "    s3, e3 = encoder_block(e2, channels_start*4, l_large=False)\n",
    "    \n",
    "    \"\"\" bridge encoder <-> decoder \"\"\"\n",
    "    b1 = conv_block(e3, channels_start*8)\n",
    "    \n",
    "    \"\"\" decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, channels_start*4)\n",
    "    d2 = decoder_block(d1, s2, channels_start*2)\n",
    "    d3 = decoder_block(d2, s1, channels_start)\n",
    "    \n",
    "    outputs = conv_block(d3, 1)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"Temp U-Net\")\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civic-michigan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Temp U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 128, 128, 2) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 56) 1064        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 56) 224         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 128, 56) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 56) 28280       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 128, 56) 224         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128, 128, 56) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 56)   0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 112)  56560       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 112)  448         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 64, 112)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 112)  0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 224)  226016      max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 224)  896         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 224)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 224)  0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 448)  903616      max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 448)  1792        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 448)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 224)  401632      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 448)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 224)  903392      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 224)  896         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 224)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 224)  451808      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 224)  896         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 224)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 112)  100464      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 224)  0           conv2d_transpose_5[0][0]         \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 112)  225904      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 112)  448         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 64, 112)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 112)  113008      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 112)  448         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 64, 112)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 56) 25144       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 112 0           conv2d_transpose_6[0][0]         \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 56) 56504       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 56) 224         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128, 128, 56) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 56) 28280       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 56) 224         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, 128, 56) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 128, 128, 1)  505         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128, 128, 1)  4           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128, 128, 1)  0           batch_normalization_29[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 3,528,901\n",
      "Trainable params: 3,525,539\n",
      "Non-trainable params: 3,362\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(128, 128, 2)\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-sending",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.0",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
