{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc16f8e2-30c8-4903-b4fc-ed12c175e21e",
   "metadata": {},
   "source": [
    "# Implementation of normalization class\n",
    "\n",
    "### Background\n",
    "To improve data normalization in MAELSTROM, a dedicated class for this job is introduced. <br>\n",
    "However, the implementation reveals some low-level bugs with xarray that are documented here.\n",
    "\n",
    "### Problem statement\n",
    "Let's start with the *errornous* approach in which we allow handling of datasets in the class. Note that this approach should work according to [xarray's documentation](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.std.html). It also works technically (i.e. it does not throw an error), but it produces strange results due to unrealistic values from the `std`-method on the dataset.\n",
    "\n",
    "The (verbose) source-code looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58144160-df72-478e-a5f4-68aa5e824354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, List\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "da_or_ds = Union[xr.DataArray, xr.Dataset]\n",
    "\n",
    "class Normalize(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for normalizing data.\n",
    "    \"\"\"\n",
    "    def __init__(self, method: str, norm_dims: List):\n",
    "        self.method = method\n",
    "        self.norm_dims = norm_dims\n",
    "        self.norm_stats = None\n",
    "\n",
    "    def normalize(self, data: xr.DataArray, **stats):\n",
    "        \n",
    "        \n",
    "        norm_stats = self.get_required_stats(data, **stats)\n",
    "        data_norm = self.normalize_data(data, *norm_stats)\n",
    "\n",
    "        return data_norm\n",
    "\n",
    "    def denormalize(self, data: da_or_ds, **stats):\n",
    "        norm_stats = self.get_required_stats(data, *stats)\n",
    "        data_denorm = self.denormalize_data(data, *norm_stats)\n",
    "\n",
    "        return data_denorm\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_required_stats(self, data, **stats):\n",
    "        \"\"\"\n",
    "        Function to retrieve either normalization parameters from data or from keyword arguments\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def normalize_data(data, *norm_param):\n",
    "        \"\"\"\n",
    "        Function to normalize data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def denormalize_data(data, *norm_param):\n",
    "        \"\"\"\n",
    "        Function to denormalize data.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d71c5a-f4b2-4659-a96b-2ec6a38860f4",
   "metadata": {},
   "source": [
    "The child class for z-score normalization looks then as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f575809e-72d0-4874-8de3-205ef6651275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZScore(Normalize):\n",
    "\n",
    "    def __init__(self, norm_dims: List):\n",
    "        super().__init__(\"z_score\", norm_dims)\n",
    "        self.norm_stats = {\"mu\": None, \"sigma\": None}\n",
    "\n",
    "    def get_required_stats(self, data: da_or_ds, **stats):\n",
    "\n",
    "        mu, std = stats.get(\"mu\", self.norm_stats[\"mu\"]), stats.get(\"sigma\", self.norm_stats[\"sigma\"])\n",
    "\n",
    "        if mu is None or std is None:\n",
    "            print(\"Retrieve mu and sigma from data...\")\n",
    "            mu, std = data.mean(self.norm_dims), data.std(self.norm_dims)\n",
    "            self.norm_stats = {\"mu\": mu, \"sigma\": std}\n",
    "            print(self.norm_stats)\n",
    "        else:\n",
    "            print(\"Mu and sigma are parsed for (de-)normalization.\")\n",
    "            print(mu)\n",
    "            print(std)\n",
    "            \n",
    "        return mu, std\n",
    "            \n",
    "    @staticmethod     \n",
    "    def normalize_data(data, mu, std):\n",
    "        data_norm = (data - mu) / std\n",
    "        \n",
    "        return data_norm\n",
    "    \n",
    "    @staticmethod     \n",
    "    def denormalize_data(data, mu, std):\n",
    "        data_denorm = data * std + mu\n",
    "        \n",
    "        return data_denorm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94372889-2588-4f74-b60a-f361ed965948",
   "metadata": {},
   "source": [
    "We load the validation data of the downscaling Tier-2 dataset for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd3c886-7c74-45a6-81ce-24ee9f0070da",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/p/project/deepacf/maelstrom/data/ap5/tier2\"\n",
    "datafile = os.path.join(datadir, \"maelstrom-downscaling-tier2_test.nc\")\n",
    "\n",
    "ds = xr.open_dataset(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d347e22-1163-49fd-a88c-805a1f9e85c2",
   "metadata": {},
   "source": [
    "Then we apply the z-score normalization on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90b057f-446b-435a-84d8-0fe1c60d18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve mu and sigma from data...\n",
      "{'mu': <xarray.Dataset>\n",
      "Dimensions:       ()\n",
      "Data variables:\n",
      "    rotated_pole  float64 1.0\n",
      "    2t_in         float32 282.8\n",
      "    sshf_in       float32 -7.078e+04\n",
      "    slhf_in       float32 -1.565e+05\n",
      "    blh_in        float32 529.6\n",
      "    10u_in        float32 0.1829\n",
      "    10v_in        float32 0.1448\n",
      "    z_in          float32 5.686e+03\n",
      "    t850_in       float32 278.6\n",
      "    t925_in       float32 282.7\n",
      "    hsurf_tar     float32 571.6\n",
      "    t_2m_tar      float32 283.2, 'sigma': <xarray.Dataset>\n",
      "Dimensions:       ()\n",
      "Data variables:\n",
      "    rotated_pole  float64 0.0\n",
      "    2t_in         float64 104.5\n",
      "    sshf_in       float64 1.973e+05\n",
      "    slhf_in       float64 2.177e+05\n",
      "    blh_in        float64 486.9\n",
      "    10u_in        float64 2.089\n",
      "    10v_in        float64 1.616\n",
      "    z_in          float64 4.809e+03\n",
      "    t850_in       float64 104.5\n",
      "    t925_in       float64 104.5\n",
      "    hsurf_tar     float64 511.0\n",
      "    t_2m_tar      float64 104.5}\n"
     ]
    }
   ],
   "source": [
    "norm_dims = [\"time\", \"rlat\", \"rlon\"]\n",
    "zscore_norm = ZScore(norm_dims)\n",
    "\n",
    "ds_norm1 = zscore_norm.normalize(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31860c01-4a87-4076-ba6a-d7aed8beb378",
   "metadata": {},
   "source": [
    "As we can see, the calculated standard deviation of the temperature variables (and others?) yields unexpected results which in would result into incorrect normalization. To prove this statement, we calculate the standard deviation manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81caad7d-55a4-4264-ae57-223ff34d7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray '2t_in' ()>\n",
      "array(9.052816, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t2m = ds[\"2t_in\"]\n",
    "sigma_t2m = np.sqrt(((t2m - t2m.mean(dim=norm_dims))**2).mean(dim=norm_dims))\n",
    "print(sigma_t2m)              # note that omitting the parameter-setting dim=norm_dims would give the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75227361-756f-44ff-bbb2-e43586f78646",
   "metadata": {},
   "source": [
    "By contrast, conversion of the dataset to a xr.DataArray, where the variables are assigned to a new dimension, gives the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32723cda-762e-4cad-9115-d11c13a96b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve mu and sigma from data...\n",
      "{'mu': <xarray.DataArray (variables: 12)>\n",
      "array([ 1.00000000e+00,  2.82832158e+02, -7.07827281e+04, -1.56503764e+05,\n",
      "        5.29617935e+02,  1.82885170e-01,  1.44832186e-01,  5.68644335e+03,\n",
      "        2.78623048e+02,  2.82670052e+02,  5.71572380e+02,  2.83245770e+02])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar', 'sigma': <xarray.DataArray (variables: 12)>\n",
      "array([0.00000000e+00, 9.05282455e+00, 2.24066973e+05, 2.36301865e+05,\n",
      "       5.11373825e+02, 2.43462441e+00, 1.87755217e+00, 4.48457913e+03,\n",
      "       7.45010479e+00, 8.21746109e+00, 4.97467674e+02, 9.03267566e+00])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar'}\n"
     ]
    }
   ],
   "source": [
    "da = ds.to_array(dim=\"variables\")\n",
    "\n",
    "zscore_norm2 = ZScore(norm_dims)     # get fresh class instance to avoid precomputed normalization parameters\n",
    "da_norm2 = zscore_norm2.normalize(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcb809-7ce7-4cf4-8f50-71564ea6fa94",
   "metadata": {},
   "source": [
    "Let's perform some further tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90de7b07-82b4-416a-b196-818880060274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu and sigma are parsed for (de-)normalization.\n",
      "282.8321579222078\n",
      "9.052824545594893\n",
      "Retrieve mu and sigma from data...\n",
      "{'mu': <xarray.DataArray '2t_in' ()>\n",
      "array(282.83246, dtype=float32), 'sigma': <xarray.DataArray '2t_in' ()>\n",
      "array(9.052816, dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "vardict = {\"variables\": \"2t_in\"}\n",
    "t2m_norm1 = da_norm2.sel(vardict)\n",
    "mu, std = zscore_norm2.norm_stats[\"mu\"].sel(vardict), zscore_norm2.norm_stats[\"sigma\"].sel(vardict)\n",
    "\n",
    "# normalize 2t_in with precomputed normalization parameters\n",
    "t2m_norm2 = zscore_norm2.normalize(t2m, mu=mu.values, sigma=std.values)\n",
    "# reset norm_stats manually...\n",
    "zscore_norm2.norm_stats = {\"mu\": None, \"sigma\": None}\n",
    "# ... to trigger computation\n",
    "t2m_norm3 = zscore_norm2.normalize(t2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5bfb410",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ds_norm1 and t2m_norm2 differ!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(t2m_norm1, t2m_norm2, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-04\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt2m_norm1 and t2m_norm2 differ!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(t2m_norm2, t2m_norm3, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-04\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt2m_norm2 and t2m_norm3 differ!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(ds_norm1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2t_in\u001b[39m\u001b[38;5;124m\"\u001b[39m], t2m_norm2, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-04\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds_norm1 and t2m_norm2 differ!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ds_norm1 and t2m_norm2 differ!"
     ]
    }
   ],
   "source": [
    "assert np.all(np.isclose(t2m_norm1, t2m_norm2, atol=1.e-04)), \"t2m_norm1 and t2m_norm2 differ!\"\n",
    "assert np.all(np.isclose(t2m_norm2, t2m_norm3, atol=1.e-04)), \"t2m_norm2 and t2m_norm3 differ!\"\n",
    "assert np.all(np.isclose(ds_norm1[\"2t_in\"], t2m_norm2, atol=1.e-04)), \"ds_norm1 and t2m_norm2 differ!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c7a1e-cd46-4d2f-996a-46028c261f5f",
   "metadata": {},
   "source": [
    "As expected, the normalized values differ substanially due to the errornous value for the standard deviataion.\n",
    "We can further trace the error which even happens when we apply the `std`-method on a Data Array with default-behaviur (i.e. without setting `dim`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e0ee471-c521-442d-9b8b-8a9a5c65a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'rlat', 'rlon']\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2018-01-01T01:00:00 ... 2018-12-31T23:00:00\n",
      "  * rlon     (rlon) float64 -8.273 -8.218 -8.163 -8.108 ... -1.838 -1.783 -1.728\n",
      "  * rlat     (rlat) float64 -3.933 -3.878 -3.823 -3.768 ... 1.182 1.237 1.292\n"
     ]
    }
   ],
   "source": [
    "print(norm_dims)\n",
    "print(ds[\"2t_in\"].coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25598bae-cad9-4a3e-be27-6791e11806c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       ()\n",
      "Data variables:\n",
      "    rotated_pole  float64 0.0\n",
      "    2t_in         float64 104.5\n",
      "    sshf_in       float64 1.973e+05\n",
      "    slhf_in       float64 2.177e+05\n",
      "    blh_in        float64 486.9\n",
      "    10u_in        float64 2.089\n",
      "    10v_in        float64 1.616\n",
      "    z_in          float64 4.809e+03\n",
      "    t850_in       float64 104.5\n",
      "    t925_in       float64 104.5\n",
      "    hsurf_tar     float64 511.0\n",
      "    t_2m_tar      float64 104.5\n",
      "<xarray.DataArray '2t_in' ()>\n",
      "array(104.4526062)\n",
      "<xarray.DataArray '2t_in' ()>\n",
      "array(9.052816, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(ds.std(skipna=True))                     # as above\n",
    "print(ds[\"2t_in\"].std(skipna=True))            # same error when retrievin 2t_in from the dataset only and defaulting .std()\n",
    "print(ds[\"2t_in\"].std(norm_dims, skipna=True))   # setting dimensions for .std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a593476-26ae-456e-a403-1cd55b7792ac",
   "metadata": {},
   "source": [
    "### The workaround\n",
    "\n",
    "In the following, we ensure that the normalization class does not work on `xr.Datasets`. Note furthermore, that `norm_dims=None` also fails since the default approach may run into the same issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca6c03ef-708a-4354-a817-057973f8f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for normalizing data.\n",
    "    \"\"\"\n",
    "    def __init__(self, method: str, norm_dims: List):\n",
    "        self.method = method\n",
    "        self.norm_dims = norm_dims\n",
    "        self.norm_stats = None\n",
    "\n",
    "    def normalize(self, data: xr.DataArray, **stats):\n",
    "        \"\"\"\n",
    "        Normalize data.\n",
    "        :param data: The DataArray to be normalized.\n",
    "        :param **stats: Parameters to perform normalization. Must fit to normalization type!\n",
    "        :return: DataArray with normalized data.\n",
    "        \"\"\"\n",
    "        # sanity checks\n",
    "        if not isinstance(data, xr.DataArray):\n",
    "            raise TypeError(f\"Passed data must be a xarray.DataArray, but is of type {str(type(data))}.\")\n",
    "            \n",
    "        _ = self._check_norm_dims(data)\n",
    "        # do the computation            \n",
    "        norm_stats = self.get_required_stats(data, **stats)\n",
    "        data_norm = self.normalize_data(data, *norm_stats)\n",
    "\n",
    "        return data_norm\n",
    "\n",
    "    def denormalize(self, data: da_or_ds, **stats):\n",
    "        \"\"\"\n",
    "        Denormalize data.\n",
    "        :param data: The DataArray to be denormalized.\n",
    "        :param **stats: Parameters to perform denormalization. Must fit to normalization type!\n",
    "        :return: DataArray with denormalized data.\n",
    "        \"\"\"\n",
    "        # sanity checks\n",
    "        if not isinstance(data, xr.DataArray):\n",
    "            raise TypeError(f\"Passed data must be a xarray.DataArray, but is of type {str(type(data))}.\")\n",
    "            \n",
    "        _ = self._check_norm_dims(data)\n",
    "        # do the computation       \n",
    "        norm_stats = self.get_required_stats(data, *stats)\n",
    "        data_denorm = self.denormalize_data(data, *norm_stats)\n",
    "\n",
    "        return data_denorm\n",
    "    \n",
    "    @property\n",
    "    def norm_dims(self):\n",
    "        return self._norm_dims\n",
    "    \n",
    "    @norm_dims.setter\n",
    "    def norm_dims(self, norm_dims):\n",
    "        if norm_dims is None:\n",
    "            raise AttributeError(\"norm_dims must not be None. Please parse a list of dimensions\" +\n",
    "                                 \"over which normalization should be applied.\")\n",
    "        \n",
    "        self._norm_dims = list(norm_dims)\n",
    "        \n",
    "    def _check_norm_dims(self, data):\n",
    "        \"\"\"\n",
    "        Check if dimension for normalization reside in dimensions of data.\n",
    "        :param data: the data (xr.DataArray) to be normalized\n",
    "        :return True: in case of passed check, a ValueError is risen else\n",
    "        \"\"\"\n",
    "        data_dims = list(data.dims)\n",
    "        norm_dims_check = [norm_dim in data_dims for norm_dim in self.norm_dims]\n",
    "        if not all(norm_dims_check):\n",
    "            imiss = np.where(~np.array(norm_dims_check))[0]\n",
    "            miss_dims = list(np.array(self.norm_dims)[imiss])\n",
    "            raise ValueError(\"The following dimensions do not reside in the data: \" +\n",
    "                             f\"{', '.join(miss_dims)}\")\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def save_norm_to_file(self, js_file):\n",
    "        \"\"\"\n",
    "        Write normalization parameters to file.\n",
    "        :param js_file: Path to JSON-file to be created.\n",
    "        :return: -\n",
    "        \"\"\"\n",
    "        if self.norm_stats is None:\n",
    "            raise AttributeError(\"norm_stats is still None. Please run (de-)normalization to get parameters.\")\n",
    "        \n",
    "        if any([stat is None for stat in self.norm_stats.values()]):\n",
    "            raise AttributeError(\"Some parameters of norm_stats are None.\")\n",
    "            \n",
    "        norm_serialized = {key: da.to_dict() for key, da in norm_dict.items()}\n",
    "        \n",
    "        with open(js_file, \"w\") as jsf:\n",
    "            js.dump(norm_dict_serialized, jsf)\n",
    "        \n",
    "    def read_norm_from_file(self, js_file):\n",
    "        \"\"\"\n",
    "        Read normalization parameters from file. Inverse function to write_norm_from_file.\n",
    "        :param js_file: Path to JSON-file to be read.\n",
    "        :return: Parameters set to self.norm_stats\n",
    "        \"\"\"\n",
    "        with open(js_file, \"r\") as jsf:\n",
    "            norm_data = js.load(jsf)\n",
    "            \n",
    "        norm_dict_restored = {key: xr.DataArray.from_dict(da_dict) for key, da_dict in norm_data.items()}\n",
    "        \n",
    "        self.norm_stats = norm_dict_restored    \n",
    "        \n",
    "\n",
    "    @abstractmethod\n",
    "    def get_required_stats(self, data, **stats):\n",
    "        \"\"\"\n",
    "        Function to retrieve either normalization parameters from data or from keyword arguments\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def normalize_data(data, *norm_param):\n",
    "        \"\"\"\n",
    "        Function to normalize data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def denormalize_data(data, *norm_param):\n",
    "        \"\"\"\n",
    "        Function to denormalize data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "class ZScore(Normalize):\n",
    "\n",
    "    def __init__(self, norm_dims: List):\n",
    "        super().__init__(\"z_score\", norm_dims)\n",
    "        self.norm_stats = {\"mu\": None, \"sigma\": None}\n",
    "\n",
    "    def get_required_stats(self, data: da_or_ds, **stats):\n",
    "        \"\"\"\n",
    "        Get required parameters for z-score normalization. They are either computed from the data \n",
    "        or can be parsed as keyword arguments.\n",
    "        :param data: the data to be (de-)normalized\n",
    "        :param mu: keyword argument for mean used for normalization\n",
    "        :param sigma: keyword argument for standard deviation for normalization\n",
    "        :return (mu, sigma): Parameters for normalization\n",
    "        \"\"\"\n",
    "        mu, std = stats.get(\"mu\", self.norm_stats[\"mu\"]), stats.get(\"sigma\", self.norm_stats[\"sigma\"])\n",
    "\n",
    "        if mu is None or std is None:\n",
    "            print(\"Retrieve mu and sigma from data...\")\n",
    "            mu, std = data.mean(self.norm_dims), data.std(self.norm_dims)\n",
    "            self.norm_stats = {\"mu\": mu, \"sigma\": std}\n",
    "            print(self.norm_stats)\n",
    "        else:\n",
    "            print(\"Mu and sigma are parsed for (de-)normalization.\")\n",
    "            print(mu)\n",
    "            print(std)\n",
    "            \n",
    "        return mu, std\n",
    "            \n",
    "    @staticmethod     \n",
    "    def normalize_data(data, mu, std):\n",
    "        \"\"\"\n",
    "        Perform z-score normalization on data\n",
    "        :param data: Data array of interest\n",
    "        :param mu: mean of data for normalization\n",
    "        :param std: standard deviation of data for normalization\n",
    "        :return data_norm: normalized data\n",
    "        \"\"\"\n",
    "        data_norm = (data - mu) / std\n",
    "        \n",
    "        return data_norm\n",
    "    \n",
    "    @staticmethod     \n",
    "    def denormalize_data(data, mu, std):\n",
    "        \"\"\"\n",
    "        Perform z-score denormalization on data.\n",
    "        :param data: Data array of interest\n",
    "        :param mu: mean of data for denormalization\n",
    "        :param std: standard deviation of data for denormalization\n",
    "        :return data_norm: denormalized data\n",
    "        \"\"\"\n",
    "        data_denorm = data * std + mu\n",
    "        \n",
    "        return data_denorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffbeecf-1472-4eb0-b679-e8c5e530fe53",
   "metadata": {},
   "source": [
    "To enable data processing, we start by converting the dataset to a data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b105ab1-7f94-43cf-b9c9-694cb78ba47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.to_array(dim=\"variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4277d55-3b4a-4a06-9453-f208aff78323",
   "metadata": {},
   "source": [
    "Let's perform various tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3862e034-632d-4969-a729-f0baa8407641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieve mu and sigma from data...\n",
      "{'mu': <xarray.DataArray (variables: 12)>\n",
      "array([ 1.00000000e+00,  2.82832158e+02, -7.07827281e+04, -1.56503764e+05,\n",
      "        5.29617935e+02,  1.82885170e-01,  1.44832186e-01,  5.68644335e+03,\n",
      "        2.78623048e+02,  2.82670052e+02,  5.71572380e+02,  2.83245770e+02])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar', 'sigma': <xarray.DataArray (variables: 12)>\n",
      "array([0.00000000e+00, 9.05282455e+00, 2.24066973e+05, 2.36301865e+05,\n",
      "       5.11373825e+02, 2.43462441e+00, 1.87755217e+00, 4.48457913e+03,\n",
      "       7.45010479e+00, 8.21746109e+00, 4.97467674e+02, 9.03267566e+00])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar'}\n"
     ]
    }
   ],
   "source": [
    "zscore_norm = ZScore([\"rlat\", \"rlon\", \"time\"])\n",
    "\n",
    "# normalize the resulting Data Array...\n",
    "da_norm = zscore_norm.normalize(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3dd17071-3c1d-4c88-90c2-f624d17b6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and compare:\n",
    "assert np.all(np.isclose(da_norm.sel({\"variables\": \"2t_in\"}), t2m_norm1, atol=1.e-06)), \"da_norm and t2m_norm1 differ!\"\n",
    "assert np.all(np.isclose(t2m_norm1, t2m_norm2, atol=1.e-04)), \"t2m_norm1 and t2m_norm2 differ!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15c6293-465d-4dac-b9ef-41fb655bc162",
   "metadata": {},
   "source": [
    "Except for spurious deviations due to changes in the normalization parameters (why ever this happens?!), the results now coincide. At least, errors smaller than 1.e-04 can also be neglected in the normalized space for our purposes which aims to project the values into a data range suitable for backpropgation in a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed27c26-b83a-4c1b-a26a-c5ebbdc7321f",
   "metadata": {},
   "source": [
    "In the following, we perform some further tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c096846d-798b-48fe-9a98-c23477ed4d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu and sigma are parsed for (de-)normalization.\n",
      "<xarray.DataArray (variables: 12)>\n",
      "array([ 1.00000000e+00,  2.82832158e+02, -7.07827281e+04, -1.56503764e+05,\n",
      "        5.29617935e+02,  1.82885170e-01,  1.44832186e-01,  5.68644335e+03,\n",
      "        2.78623048e+02,  2.82670052e+02,  5.71572380e+02,  2.83245770e+02])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar'\n",
      "<xarray.DataArray (variables: 12)>\n",
      "array([0.00000000e+00, 9.05282455e+00, 2.24066973e+05, 2.36301865e+05,\n",
      "       5.11373825e+02, 2.43462441e+00, 1.87755217e+00, 4.48457913e+03,\n",
      "       7.45010479e+00, 8.21746109e+00, 4.97467674e+02, 9.03267566e+00])\n",
      "Coordinates:\n",
      "  * variables  (variables) <U12 'rotated_pole' '2t_in' ... 't_2m_tar'\n"
     ]
    }
   ],
   "source": [
    "js_file = \"./test.json\"\n",
    "\n",
    "# save normalization parameters to file\n",
    "zscore_norm.save_norm_to_file(js_file)\n",
    "\n",
    "# instantiate fresh instance and get normalization parameters from file\n",
    "zscore_norm_new = ZScore([\"rlat\", \"rlon\", \"time\"])\n",
    "zscore_norm_new.read_norm_from_file(js_file)\n",
    "\n",
    "# apply normalization without retrieval from data (see print-statement!)\n",
    "da_norm = zscore_norm_new.normalize(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6cd6c-80ff-4bac-b4e1-fa02e40ac4af",
   "metadata": {},
   "source": [
    "Finally check, if we still obtain the expected result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0059570f-e5c8-41e5-8992-2eeb3786e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(da_norm.sel({\"variables\": \"2t_in\"}), t2m_norm1, atol=1.e-06)), \"da_norm and t2m_norm1 differ!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a8835-1be2-480e-9443-26c13fba8f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langguth1_downscaling_kernel_juwels",
   "language": "python",
   "name": "langguth1_downscaling_kernel_juwels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
