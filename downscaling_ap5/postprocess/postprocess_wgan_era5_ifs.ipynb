{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185e6a0b-fe7d-4727-9e66-69debc18bbcd",
   "metadata": {},
   "source": [
    "# Postprocessing trained downscaling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303bec6-8cc5-46ee-8775-3f98038fcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../models/\")\n",
    "sys.path.append(\"../utils/\")\n",
    "sys.path.append(\"../handle_data/\")\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from handle_data_unet import *\n",
    "from handle_data_class import  *\n",
    "from statistical_evaluation import Scores\n",
    "from plotting import *\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json as js\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb03821-0602-453f-bbf6-7e2bd105ca84",
   "metadata": {},
   "source": [
    "## Base directories for test dataset and model\n",
    "\n",
    "Adapt `datadir`, `model_base_dir` and `model_name`.\n",
    " - `datadir`: directory where the test dataset is stored\n",
    " - `model_base_dir`: top-level directory where trained downscaling models are saved\n",
    " - `model_name`: name of trained model\n",
    " - `lztar`: flag if high-resolved (target) topography is part of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326facd-5f1f-4f74-861c-cff1ab255c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/p/scratch/deepacf/maelstrom/maelstrom_data/ap5_michael/preprocessed_era5_crea6/netcdf_data/all_files/\"\n",
    "model_base_dir = \"/p/home/jusers/langguth1/juwels/downscaling_maelstrom/downscaling_jsc_repo/downscaling_ap5/trained_models\"\n",
    "# name of the model to be postprocessed\n",
    "model_name = \"wgan_era5_to_crea6_epochs40_supervision_ztar2in_noes2\"\n",
    "lztar = True\n",
    "\n",
    "# constrct model directory paths\n",
    "model_base = os.path.join(model_base_dir, model_name)\n",
    "model_dir = os.path.join(model_base, f\"{model_name}_generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9ba3-19cc-4dcc-9af8-4c85508ba9c0",
   "metadata": {},
   "source": [
    "Next, we load the model and also retrieve the testing dataset by reading the corresponding netCDF-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f028ee9-b707-4292-ba45-ed231143392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Load model '{model_name}'\")\n",
    "trained_model = keras.models.load_model(model_dir, compile=False)\n",
    "print(f\"Read training dataset from {data_dir}\") \n",
    "ds_test = xr.open_dataset(os.path.join(data_dir, \"preproc_era5_crea6_test.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0f8af-2954-4048-bbb1-1445038a9325",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "After retrieving the reference data (i.e. the ground truth data)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d2954-d4a6-4832-8710-36d918efb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ds_test[\"t_2m_tar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b567b0-dc0e-4cb5-87e0-b5449da3b06b",
   "metadata": {},
   "source": [
    "... we preprocess the input from the test dataset. For this, the data is reshaped into a xarray DataArray whose last dimension corresponds to the variables (the feature channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f4307-3dbb-4073-8001-9c425ee3bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the normalization parameters from saved json file\n",
    "js_norm = os.path.join(model_dir, \"..\", \"z_norm_dict.json\")\n",
    "\n",
    "try:\n",
    "    with open(js_norm, \"r\") as f:\n",
    "        norm_dict = js.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Could not find '{js_norm}'. Please check model-directory '{model_dir}'.\")\n",
    "\n",
    "train_vars = list(ds_test.keys())\n",
    "mu_train, std_train = np.asarray(norm_dict[\"mu\"]), np.asarray(norm_dict[\"std\"])\n",
    "da_test = HandleDataClass.reshape_ds(ds_test)\n",
    "da_test = HandleUnetData.z_norm_data(da_test, norm_method=\"norm\", save_path=model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2da370-7b1c-4fda-a4b2-2cb278d1db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the inputs and the target data\n",
    "da_test_in, da_test_tar = HandleDataClass.split_in_tar(da_test)\n",
    "if lztar:\n",
    "    print(\"Add high-resolved target topography to input features.\")\n",
    "    da_test_in = xr.concat([da_test_in, da_test_tar.sel({\"variables\": \"hsurf_tar\"})], dim=\"variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ecab4-c0eb-4519-ba27-637c81bdab14",
   "metadata": {},
   "source": [
    "## Create predictions from trained model\n",
    "\n",
    "The preprocessed data is fed into the trained model to obtain the downscalted 2m tmepertaure which is subject to evaluation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68429da6-fc6e-4ec2-a400-4345e496c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start inference from trained model...\")\n",
    "y_pred_trans =  trained_model.predict(da_test_in.squeeze().values, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec3e28-72df-45b1-9c56-0651bbeb67c7",
   "metadata": {},
   "source": [
    "For evaluation, we have to denormalize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4f144-588c-4357-8d10-33ece738f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates and dimensions from target data\n",
    "coords = da_test_tar.isel(variables=0).squeeze().coords\n",
    "dims = da_test_tar.isel(variables=0).squeeze().dims\n",
    "y_pred = xr.DataArray(y_pred_trans[0].squeeze(), coords=coords, dims=dims)\n",
    "# perform denormalization\n",
    "y_pred = HandleUnetData.denormalize(y_pred.squeeze(), \n",
    "                                    norm_dict[\"mu\"][\"t_2m_tar\"], \n",
    "                                    norm_dict[\"std\"][\"t_2m_tar\"])\n",
    "y_pred = xr.DataArray(y_pred, coords=coords, dims=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cac8dc-cc46-4976-b3de-718cd740ce14",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Subsequently, the produced downscaling product is evaluated using the following scores\n",
    "- RMSE\n",
    "- Bias\n",
    "- Horizontal gradient ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c9829-333e-4b62-89a2-fefa74136a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_plot(data: xr.DataArray, data_std: xr.DataArray, model_name: str, metric: dict,\n",
    "                     filename: str):\n",
    "    \n",
    "    fig, (ax) = plt.subplots(1,1)\n",
    "    ax.plot(data[\"hour\"].values, data.values, 'k-', label=model_name)\n",
    "    ax.fill_between(data[\"hour\"].values, data.values-data_std.values, data.values+data_std.values, facecolor=\"blue\", alpha=0.2)\n",
    "    ax.set_ylim(0.,4.)\n",
    "    # label axis\n",
    "    ax.set_xlabel(\"daytime [UTC]\", fontsize=16)\n",
    "    metric_name, metric_unit = list(metric.keys())[0], list(metric.values())[0]\n",
    "    ax.set_ylabel(f\"{metric_name} T2m [{metric_unit}]\", fontsize=16)\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=14)\n",
    "\n",
    "    # save plot to file\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcbc447-29a8-428a-a93f-c2fff39cb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get plot directory\n",
    "plot_dir = os.path.join(\".\", model_name)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "avg_dims = [\"rlat\", \"rlon\"]\n",
    "# instantiate score engine\n",
    "score_engine = Scores(y_pred, ground_truth, avg_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ec108-d81c-401c-8d92-f9df5fd2a661",
   "metadata": {},
   "source": [
    "Now, we start to create the RMSE-plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183d6d1-4c8c-4f50-bd6f-fb817456ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rmse\n",
    "rmse_all = score_engine(\"rmse\")\n",
    "\n",
    "rmse_hourly_all = rmse_all.groupby(\"time.hour\")\n",
    "rmse_hourly_mean, rmse_hourly_std = rmse_hourly_all.mean(), rmse_hourly_all.std()\n",
    "for hh in range(24):\n",
    "    if hh == 0:\n",
    "        tmp = rmse_all.isel({\"time\": rmse_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        rmse_hourly_mean_sea, rmse_hourly_std_sea = tmp.mean(), tmp.std()\n",
    "    else:\n",
    "        tmp = rmse_all.isel({\"time\": rmse_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        rmse_hourly_mean_sea, rmse_hourly_std_sea = xr.concat([rmse_hourly_mean_sea, tmp.mean()], dim=\"hour\"), \\\n",
    "                                                    xr.concat([rmse_hourly_std_sea, tmp.std()], dim=\"hour\")\n",
    "   \n",
    "# create RMSE plots                                  \n",
    "create_line_plot(rmse_hourly_mean, rmse_hourly_std, \"WGAN\",\n",
    "                 {\"RMSE\": \"K\"}, os.path.join(plot_dir, \"downscaling_wgan_rmse.png\"))\n",
    "\n",
    "for sea in rmse_hourly_mean_sea[\"season\"]:\n",
    "    create_line_plot(rmse_hourly_mean_sea.sel({\"season\": sea}), \n",
    "                     rmse_hourly_mean_sea.sel({\"season\": sea}),\n",
    "                     \"WGAN\", {\"RMSE\": \"K\"},\n",
    "                     os.path.join(plot_dir, f\"downscaling_wgan_rmse_{sea.values}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc3edc-27d5-4611-9530-f96f201e72a1",
   "metadata": {},
   "source": [
    "Next, the Bias gets visualized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2161da-c4c7-4b63-ae4e-8f1cbe95aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bias\n",
    "bias_all = score_engine(\"bias\")\n",
    "\n",
    "bias_hourly_all = bias_all.groupby(\"time.hour\")\n",
    "bias_hourly_mean, bias_hourly_std = bias_hourly_all.mean(), bias_hourly_all.std()\n",
    "for hh in range(24):\n",
    "    if hh == 0:\n",
    "        tmp = bias_all.isel({\"time\": bias_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        bias_hourly_mean_sea, bias_hourly_std_sea = tmp.mean(), tmp.std()\n",
    "    else:\n",
    "        tmp = bias_all.isel({\"time\": bias_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        bias_hourly_mean_sea, bias_hourly_std_sea = xr.concat([bias_hourly_mean_sea, tmp.mean()], dim=\"hour\"), \\\n",
    "                                                    xr.concat([bias_hourly_std_sea, tmp.std()], dim=\"hour\")\n",
    "   \n",
    "# create RMSE plots                                  \n",
    "create_line_plot(bias_hourly_mean, bias_hourly_std, \"WGAN\",\n",
    "                 {\"Bias\": \"K\"}, os.path.join(plot_dir, \"downscaling_wgan_bias.png\"))\n",
    "\n",
    "for sea in bias_hourly_mean_sea[\"season\"]:\n",
    "    create_line_plot(bias_hourly_mean_sea.sel({\"season\": sea}), \n",
    "                     bias_hourly_mean_sea.sel({\"season\": sea}),\n",
    "                     \"WGAN\", {\"Bias\": \"K\"},\n",
    "                     os.path.join(plot_dir, f\"downscaling_wgan_bias_{sea.values}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8729b-76dd-4d59-b6b3-ddc7c8d92cfe",
   "metadata": {},
   "source": [
    "Finally, the spatial variability gets evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e11277-6a82-459a-936d-917e77494910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bias\n",
    "grad_all = score_engine(\"grad_amplitude\")\n",
    "\n",
    "grad_hourly_all = grad_all.groupby(\"time.hour\")\n",
    "grad_hourly_mean, grad_hourly_std = grad_hourly_all.mean(), grad_hourly_all.std()\n",
    "for hh in range(24):\n",
    "    if hh == 0:\n",
    "        tmp = grad_all.isel({\"time\": grad_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        grad_hourly_mean_sea, grad_hourly_std_sea = tmp.mean(), tmp.std()\n",
    "    else:\n",
    "        tmp = grad_all.isel({\"time\": grad_all.time.dt.hour == hh}).groupby(\"time.season\")\n",
    "        grad_hourly_mean_sea, grad_hourly_std_sea = xr.concat([grad_hourly_mean_sea, tmp.mean()], dim=\"hour\"), \\\n",
    "                                                    xr.concat([grad_hourly_std_sea, tmp.std()], dim=\"hour\")\n",
    "   \n",
    "# create RMSE plots                                  \n",
    "create_line_plot(grad_hourly_mean, grad_hourly_std, \"WGAN\",\n",
    "                 {\"Gradient ratio\": \"1\"}, os.path.join(plot_dir, \"downscaling_wgan_grad_rat.png\"))\n",
    "\n",
    "for sea in grad_hourly_mean_sea[\"season\"]:\n",
    "    create_line_plot(grad_hourly_mean_sea.sel({\"season\": sea}), \n",
    "                     grad_hourly_std_sea.sel({\"season\": sea}),\n",
    "                     \"WGAN\", {\"Gradient ratio\": \"1\"},\n",
    "                     os.path.join(plot_dir, f\"downscaling_wgan_grad_rat_{sea.values}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51f418-6d50-42b7-932e-9a513b5fda2b",
   "metadata": {},
   "source": [
    "## Evaluation with map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TO-DO ########## \n",
    "\n",
    "y_pred_eval = y_pred_trans#.sel(time=dt.time(12))\n",
    "\n",
    "# plot the full 2m temperature\n",
    "plt_fname_exp = \"./plot_temp_pred_real\"\n",
    "create_plots(y_pred_eval.isel(time=tind), ds_test[\"t2m_tar\"].isel(time=tind), plt_fname_exp,\n",
    "             opt_plot={\"title1\": \"downscaled T2m\", \"title2\": \"target T2m\", \"levels\": np.arange(-3, 27., 1.)})\n",
    "\n",
    "plt_fname_diff = \"./plot_temp_diff\"\n",
    "diff_in_tar = ds_test[\"2t_in\"].isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "diff_down_tar = y_pred_eval.isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "create_plots(diff_in_tar, diff_down_tar, plt_fname_diff,\n",
    "             opt_plot={\"title1\": \"diff. input-target\", \"title2\": \"diff. downscaled-target\",\n",
    "                       \"levels\": np.arange(-3., 3.1, .2)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langguth1_downscaling_kernel_juwels",
   "language": "python",
   "name": "langguth1_downscaling_kernel_juwels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
