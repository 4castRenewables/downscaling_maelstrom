{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185e6a0b-fe7d-4727-9e66-69debc18bbcd",
   "metadata": {},
   "source": [
    "# Postprocessing trained downscaling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9303bec6-8cc5-46ee-8775-3f98038fcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../models/\")\n",
    "sys.path.append(\"../utils/\")\n",
    "sys.path.append(\"../handle_data/\")\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from handle_data_unet import *\n",
    "from handle_data_class import  *\n",
    "from plotting import *\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json as js\n",
    "import gc\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb03821-0602-453f-bbf6-7e2bd105ca84",
   "metadata": {},
   "source": [
    "## Base directories for test dataset and model\n",
    "\n",
    "Adapt `datadir`, `model_base_dir` and `model_name`.\n",
    " - `datadir`: directory where the test dataset is stored\n",
    " - `model_base_dir`: top-level directory where trained downscaling models are saved\n",
    " - `model_name`: name of trained model\n",
    " - `lztar`: flag if high-resolved (target) topography is part of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f326facd-5f1f-4f74-861c-cff1ab255c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/p/scratch/deepacf/maelstrom/maelstrom_data/ap5_michael/preprocessed_era5_crea6/netcdf_data/all_files/\"\n",
    "model_base_dir = \"/p/home/jusers/langguth1/juwels/downscaling_maelstrom/downscaling_jsc_repo/downscaling_ap5/trained_models\"\n",
    "# name of the model to be postprocessed\n",
    "model_name = \"wgan_era5_to_crea6_epochs40_supervision_ztar2in_noes\"\n",
    "lztar = True\n",
    "\n",
    "# constrct model directory paths\n",
    "model_base = os.path.join(model_base_dir, model_name)\n",
    "model_dir = os.path.join(model_base, f\"{model_name}_generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d9ba3-19cc-4dcc-9af8-4c85508ba9c0",
   "metadata": {},
   "source": [
    "Next, we load the model and also retrieve the testing dataset by reading the corresponding netCDF-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f028ee9-b707-4292-ba45-ed231143392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model 'wgan_era5_to_crea6_epochs40_supervision_ztar2in_noes'\n",
      "Read training dataset from /p/scratch/deepacf/maelstrom/maelstrom_data/ap5_michael/preprocessed_era5_crea6/netcdf_data/all_files/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Load model '{model_name}'\")\n",
    "trained_model = keras.models.load_model(model_dir, compile=False)\n",
    "print(f\"Read training dataset from {datadir}\") \n",
    "ds_test = xr.open_dataset(os.path.join(data_dir, \"preproc_era5_crea6_test.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0f8af-2954-4048-bbb1-1445038a9325",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "After retrieving the reference data (i.e. the ground truth data)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c4d2954-d4a6-4832-8710-36d918efb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ds_test[\"t_2m_tar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b567b0-dc0e-4cb5-87e0-b5449da3b06b",
   "metadata": {},
   "source": [
    "... we preprocess the input from the test dataset. For this, the data is reshaped into a xarray DataArray whose last dimension corresponds to the variables (the feature channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71f4307-3dbb-4073-8001-9c425ee3bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read parameters for normalization from file /p/home/jusers/langguth1/juwels/downscaling_maelstrom/downscaling_jsc_repo/downscaling_ap5/trained_models/wgan_era5_to_crea6_epochs40_supervision_ztar2in_noes2/z_norm_dict.json...\n"
     ]
    }
   ],
   "source": [
    "# Get the normalization parameters from saved json file\n",
    "js_norm = os.path.join(model_dir, \"..\", \"z_norm_dict.json\")\n",
    "\n",
    "try:\n",
    "    with open(js_norm, \"r\") as f:\n",
    "        norm_dict = js.load(f)\n",
    "except FileNotFoundError as e:\n",
    "    raise FileNotFoundError(f\"Could not find '{js_norm}'. Please check model-directory '{model_dir}'.\")\n",
    "\n",
    "train_vars = list(ds_test.keys())\n",
    "mu_train, std_train = np.asarray(norm_dict[\"mu\"]), np.asarray(norm_dict[\"std\"])\n",
    "da_test = HandleDataClass.reshape_ds(ds_test)\n",
    "da_test = HandleUnetData.z_norm_data(da_test, norm_method=\"norm\", save_path=model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae2da370-7b1c-4fda-a4b2-2cb278d1db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add high-resolved target topography to input features.\n"
     ]
    }
   ],
   "source": [
    "# Split the inputs and the target data\n",
    "da_test_in, da_test_tar = HandleDataClass.split_in_tar(da_test)\n",
    "if lztar:\n",
    "    print(\"Add high-resolved target topography to input features.\")\n",
    "    da_test_in = xr.concat([da_test_in, da_test_tar.sel({\"variables\": \"hsurf_tar\"})], dim=\"variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ecab4-c0eb-4519-ba27-637c81bdab14",
   "metadata": {},
   "source": [
    "## Create predictions from trained model\n",
    "\n",
    "The preprocessed data is fed into the trained model to obtain the downscalted 2m tmepertaure which is subject to evaluation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "68429da6-fc6e-4ec2-a400-4345e496c726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference from trained model...\n",
      "274/274 [==============================] - 167s 609ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Start inference from trained model...\")\n",
    "y_pred_trans =  trained_model.predict(da_test_in.squeeze().values, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec3e28-72df-45b1-9c56-0651bbeb67c7",
   "metadata": {},
   "source": [
    "For evaluation, we have to denormalize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ea4f144-588c-4357-8d10-33ece738f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for normalization are parsed directly to the method.\n"
     ]
    }
   ],
   "source": [
    "# get coordinates and dimensions from target data\n",
    "coords = da_test_tar.isel(variables=0).squeeze().coords\n",
    "dims = da_test_tar.isel(variables=0).squeeze().dims\n",
    "y_pred = xr.DataArray(y_pred_trans[0].squeeze(), coords=coords, dims=dims)\n",
    "# perform denormalization\n",
    "y_pred = HandleUnetData.denormalize(y_pred.squeeze(), \n",
    "                                    norm_dict[\"mu\"][\"t_2m_tar\"], \n",
    "                                    norm_dict[\"std\"][\"t_2m_tar\"])\n",
    "y_pred = xr.DataArray(y_pred, coords=coords, dims=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cac8dc-cc46-4976-b3de-718cd740ce14",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Subsequently, the produced downscaling product is evaluated using the following scores\n",
    "- MSE\n",
    "- Bias\n",
    "- Horizontal gradient ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca3930b1-0be2-4a7e-8e36-3faa85e5244e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.time' has no attribute 'season'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseason\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJJA\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'datetime.time' has no attribute 'season'"
     ]
    }
   ],
   "source": [
    "print(y_pred.sel(time=dt.time.season(\"JJA\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "507378d0-2a3d-4af0-9d59-e94f060e3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "mse_mean, mse_std = np.zeros(24), np.zeros(24)\n",
    "mse_mean_sea, mse_std_sea = np.zeros((4, 24)), np.zeros((4, 24))\n",
    "\n",
    "for i, hh in enumerate(np.arange(0, 24)):\n",
    "    mse_all = ((y_pred.sel(time=dt.time(hh)) - ground_truth.sel(time=dt.time(hh)))**2).mean(dim=[\"rlat\", \"rlon\"])\n",
    "    mse_mean[i], mse_std[i] = mse_all.mean().values, mse_all.std().values\n",
    "    mse_mean_sea[:,i], mse_std_sea[:,i] = mse_all.groupby(\"time.season\").mean().values, \\\n",
    "                                          mse_all.groupby(\"time.season\").std().values \n",
    "    \n",
    "mse_mean = xr.DataArray(mse_mean, coords = {\"daytime\": np.arange(0,24)}, dims=[\"daytime\"]) \n",
    "mse_std = xr.DataArray(mse_std, coords = {\"daytime\": np.arange(0,24)}, dims=[\"daytime\"])\n",
    "\n",
    "\n",
    "mse_mean_sea = xr.DataArray(mse_mean_sea, coords = {\"season\": seasons, \"daytime\": np.arange(0,24)},\n",
    "                            dims = [\"season\", \"daytime\"])\n",
    "mse_std_sea = xr.DataArray(mse_std_sea, coords = {\"season\": seasons, \"daytime\": np.arange(0,24)},\n",
    "                            dims = [\"season\", \"daytime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51f418-6d50-42b7-932e-9a513b5fda2b",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06c70e1d-2a2f-4a86-8107-265b3e676f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_plot(data: xr.DataArray, data_std: xr.DataArray, model_name: str, metric: dict,\n",
    "                     filename: str):\n",
    "    \n",
    "    fig, (ax) = plt.subplots(1,1)\n",
    "    ax.plot(data[\"daytime\"].values, data.values, 'k-', label=model_name)\n",
    "    ax.fill_between(data[\"daytime\"].values, data.values-data_std.values, data.values+data_std.values, facecolor=\"blue\", alpha=0.2)\n",
    "    ax.set_ylim(0.,4.)\n",
    "    # label axis\n",
    "    ax.set_xlabel(\"daytime [UTC]\", fontsize=16)\n",
    "    metric_name, metric_unit = list(metric.keys())[0], list(metric.values())[0]\n",
    "    ax.set_ylabel(f\"{metric_name} T2m [{metric_unit}]\", fontsize=16)\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=14)\n",
    "\n",
    "    ax.legend(handles, labels, loc='upper right', numpoints=1)\n",
    "    # save plot to file\n",
    "    fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10c195af-0bd8-4a76-acfe-cb056ee4b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = os.path.join(\".\", model_name)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "create_line_plot(np.sqrt(mse_mean), np.sqrt(mse_std), \"WGAN\",\n",
    "                 {\"RMSE\": \"K\"}, os.path.join(plot_dir, \"downscaling_wgan_rmse.png\"))\n",
    "\n",
    "for sea in seasons:\n",
    "    create_line_plot(np.sqrt(mse_mean_sea.sel({\"season\": sea})), \n",
    "                     np.sqrt(mse_std_sea.sel({\"season\": sea})),\n",
    "                     \"WGAN\", {\"RMSE\": \"K\"},\n",
    "                     os.path.join(plot_dir, f\"downscaling_wgan_rmse_{sea}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a time index\n",
    "tind = 380\n",
    "\n",
    "y_pred_eval = y_pred_trans#.sel(time=dt.time(12))\n",
    "\n",
    "# plot the full 2m temperature\n",
    "plt_fname_exp = \"./plot_temp_pred_real\"\n",
    "create_plots(y_pred_eval.isel(time=tind), ds_test[\"t2m_tar\"].isel(time=tind), plt_fname_exp,\n",
    "             opt_plot={\"title1\": \"downscaled T2m\", \"title2\": \"target T2m\", \"levels\": np.arange(-3, 27., 1.)})\n",
    "\n",
    "plt_fname_diff = \"./plot_temp_diff\"\n",
    "diff_in_tar = ds_test[\"2t_in\"].isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "diff_down_tar = y_pred_eval.isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "create_plots(diff_in_tar, diff_down_tar, plt_fname_diff,\n",
    "             opt_plot={\"title1\": \"diff. input-target\", \"title2\": \"diff. downscaled-target\",\n",
    "                       \"levels\": np.arange(-3., 3.1, .2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-breast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ecc27-62ac-4c0e-9215-e00f9c6217eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langguth1_downscaling_kernel_juwels",
   "language": "python",
   "name": "langguth1_downscaling_kernel_juwels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
