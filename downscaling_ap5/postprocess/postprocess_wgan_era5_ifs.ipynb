{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metropolitan-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../models/\")\n",
    "sys.path.append(\"../utils/\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# all the layers used for U-net\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D, Dense, Flatten, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from unet_model import build_unet, conv_block\n",
    "from wgan_model import *\n",
    "from plotting import *\n",
    "from other_utils import provide_default\n",
    "\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import climetlab as cml \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import json as js\n",
    "import gc\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e79442-cdda-4292-9dd2-5ce789f6e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326facd-5f1f-4f74-861c-cff1ab255c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/p/scratch/deepacf/maelstrom/maelstrom_data/ap5_michael/preprocessed_era5_ifs/netcdf_data/all_files/\"\n",
    "\n",
    "ds_train = xr.open_dataset(os.path.join(datadir, \"era5_to_ifs_train_corrected.nc\"))\n",
    "ds_test = xr.open_dataset(os.path.join(datadir, \"era5_to_ifs_test_corrected.nc\"))\n",
    "                      \n",
    "print(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31672dd-4901-4b13-a11c-2a46cf909aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"wgan_lrdecay_test\"\n",
    "\n",
    "savedir = os.path.join(\"../trained_models/\", modelname)\n",
    "if not os.path.isdir(os.path.join(savedir, f\"{modelname}_generator\")) or not os.path.isdir(os.path.join(savedir, f\"{modelname}_critic\")):\n",
    "    raise ValueError(\"Cannot find generator and critic model '{0}' under '{1}' to postprocess.\".format(modelname, savedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c3a416-8d13-4adf-a561-19153011ba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 21:54:12.960833: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-30 21:54:12.960890: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jwlogin02.juwels): /proc/driver/nvidia/version does not exist\n",
      "2022-06-30 21:54:12.962424: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "wgan_generator = keras.models.load_model(os.path.join(savedir, f\"{modelname}_generator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan_model = WGAN(build_unet, critic_model, {\"lr_decay\": True, \"lr\": 5.e-06, \"train_epochs\": 10,\n",
    "                                             \"recon_weight\": 1000., \"d_steps\": 6, \"optimizer\": \"adam\",\n",
    "                                             \"z_branch\": True, \"gp_weight\": 10.})\n",
    "\n",
    "# Load the previously saved weights\n",
    "latest = tf.train.latest_checkpoint(savedir)\n",
    "wgan_model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clinical-journalist",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../trained_models/wgan_lrdecay_test/norm_dict.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m js_norm \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(savedir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_dict.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m norm_dims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjs_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     norm_dict \u001b[38;5;241m=\u001b[39m js\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m train_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ds_train\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../trained_models/wgan_lrdecay_test/norm_dict.json'"
     ]
    }
   ],
   "source": [
    "js_norm = os.path.join(savedir, \"norm_dict.json\")\n",
    "norm_dims = [\"time\", \"lat\", \"lon\"]\n",
    "\n",
    "with open(js_norm, \"r\") as f:\n",
    "    norm_dict = js.load(f)\n",
    "    \n",
    "train_vars = list(ds_train.keys())\n",
    "mu_train, std_train = np.asarray(norm_dict[\"mu_train\"]), np.asarray(norm_dict[\"std_train\"])\n",
    "mu_train = xr.DataArray(mu_train, coords={\"variables\": train_vars}, dims=[\"variables\"])\n",
    "std_train = xr.DataArray(std_train, coords={\"variables\": train_vars}, dims=[\"variables\"])\n",
    "\n",
    "da_test = reshape_ds(ds_test)\n",
    "da_test = z_norm_data(da_test, mu=mu_train, std=std_train)\n",
    "\n",
    "da_test_in, da_test_tar = WGAN.split_in_tar(da_test)\n",
    "test_iter = tf.data.Dataset.from_tensor_slices((da_test_in, da_test_tar))\n",
    "test_iter = test_iter.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = wgan_model.compile(da_test.astype(np.float32), da_test.astype(np.float32))\n",
    "y_pred = wgan_model.predict(test_iter, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to xarray and denormalize\n",
    "coords = da_test.isel(variables=0).squeeze().coords\n",
    "dims = da_test.isel(variables=0).squeeze().dims\n",
    "\n",
    "y_pred_trans = xr.DataArray(y_pred[0].squeeze(), coords=coords, dims=dims)\n",
    "\n",
    "y_pred_trans = y_pred_trans.squeeze()*std_train[0].squeeze() + mu_train[0].squeeze()\n",
    "y_pred_trans = xr.DataArray(y_pred_trans, coords=coords, dims=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_mean, mse_std = np.zeros(24), np.zeros(24)\n",
    "\n",
    "for i, hh in enumerate(np.arange(0, 24)):\n",
    "    mse_all = ((y_pred_trans.sel(time=dt.time(hh)) - ds_test[\"t2m_tar\"].sel(time=dt.time(hh)))**2).mean(dim=[\"lat\", \"lon\"])\n",
    "    mse_mean[i], mse_std[i] = mse_all.mean().values, mse_all.std().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((y_pred_trans - ds_test[\"t2m_tar\"])**2).mean(dim=[\"lat\", \"lon\"])\n",
    "\n",
    "print(mse.argmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "mse_mean = xr.DataArray(mse_mean, coords = {\"daytime\": np.arange(0,24)}, dims=[\"daytime\"]) \n",
    "mse_std = xr.DataArray(mse_std, coords = {\"daytime\": np.arange(0,24)}, dims=[\"daytime\"])\n",
    "\n",
    "mse_mean_v, mse_std_v = mse_mean.values, mse_std.values\n",
    "fig, (ax) = plt.subplots(1,1)\n",
    "ax.plot(mse_mean[\"daytime\"].values, mse_mean_v, 'k-', label=\"ERA5 DeepHRES\")\n",
    "ax.fill_between(mse_mean[\"daytime\"].values, mse_mean_v-mse_std_v, mse_mean_v+mse_std_v, facecolor=\"blue\", alpha=0.2)\n",
    "ax.set_ylim(0.,4.)\n",
    "# label axis\n",
    "ax.set_xlabel(\"daytime [UTC]\", fontsize=16)\n",
    "ax.set_ylabel(\"MSE T2m [K$^2$]\", fontsize=16)\n",
    "ax.tick_params(axis=\"both\", which=\"both\", direction=\"out\", labelsize=14)\n",
    "\n",
    "## add MSE from previous non-augmented dataset\n",
    "#ax.errorbar(12, 0.394, yerr=0.094, fmt='x', capsize=5., ecolor=\"black\", mfc=\"red\",\n",
    "#            mec=\"red\", ms=10, mew=2., label = \"Unet small\")\n",
    "# Configure legend\n",
    "# get handles\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# remove the errorbars\n",
    "#handles[1] = handles[1][0]\n",
    "\n",
    "ax.legend(handles, labels, loc='upper right', numpoints=1)\n",
    "# save plot to file\n",
    "fig.savefig(\"downscaling_wgan_t2m_mse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a time index\n",
    "tind = 380\n",
    "\n",
    "y_pred_eval = y_pred_trans#.sel(time=dt.time(12))\n",
    "\n",
    "# plot the full 2m temperature\n",
    "plt_fname_exp = \"./plot_temp_pred_real\"\n",
    "create_plots(y_pred_eval.isel(time=tind), ds_test[\"t2m_tar\"].isel(time=tind), plt_fname_exp,\n",
    "             opt_plot={\"title1\": \"downscaled T2m\", \"title2\": \"target T2m\", \"levels\": np.arange(-3, 27., 1.)})\n",
    "\n",
    "plt_fname_diff = \"./plot_temp_diff\"\n",
    "diff_in_tar = ds_test[\"2t_in\"].isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "diff_down_tar = y_pred_eval.isel(time=tind)-ds_test[\"t2m_tar\"].isel(time=tind) + 273.15\n",
    "create_plots(diff_in_tar, diff_down_tar, plt_fname_diff,\n",
    "             opt_plot={\"title1\": \"diff. input-target\", \"title2\": \"diff. downscaled-target\",\n",
    "                       \"levels\": np.arange(-3., 3.1, .2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-breast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langguth1_downscaling_kernel_juwels",
   "language": "python",
   "name": "langguth1_downscaling_kernel_juwels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
