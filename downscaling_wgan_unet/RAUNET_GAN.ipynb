{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8209ce-d4f6-40ce-9255-c26d9a1d8320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 09:20:55.256802: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import xarray as xr\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.utils import *\n",
    "from tensorflow.python.keras import backend as K\n",
    "import pickle\n",
    "import copy\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7e8ea3-ef44-4ccf-ab3b-e6d9c31494cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17474b9-e4e7-4871-8bd0-f09eae34ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ef37ebf-a0c7-4615-a1ef-0c4b1808e883",
   "metadata": {},
   "source": [
    "## Load NWP and observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0fb466-12f8-48ae-b3e6-d53ecc71bb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'init_time' (init_time: 1420)>\n",
      "array([18040100., 18040106., 18040112., ..., 19093006., 19093012., 19093018.])\n",
      "Coordinates:\n",
      "    time       float64 ...\n",
      "  * init_time  (init_time) float64 1.804e+07 1.804e+07 ... 1.909e+07 1.909e+07\n",
      "    lead_hour  int32 ...\n",
      "<xarray.DataArray 'init_time' (init_time: 724)>\n",
      "array([20040100., 20040106., 20040112., ..., 20093006., 20093012., 20093018.])\n",
      "Coordinates:\n",
      "    time       float64 ...\n",
      "  * init_time  (init_time) float64 2.004e+07 2.004e+07 ... 2.009e+07 2.009e+07\n",
      "    lead_hour  int32 ...\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# load data\n",
    "leadtimelist = ['00','01','02','03','04','05','06', \\\n",
    "    '07','08','09','10','11','12', \\\n",
    "    '13','14','15','16','17','18', \\\n",
    "    '19','20','21','22','23','24']\n",
    "leadhour = 1\n",
    "leadtime = leadtimelist[leadhour]\n",
    "prefix = '/p/scratch/deepacf/deeprain/ji4/Beijing_Unet/FCNdata'\n",
    "save_dir = os.path.join(prefix,'Results',leadtime,'exp27')\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "\n",
    "filepath = os.path.join(prefix,'PT_vars_Train.nc')\n",
    "with xr.open_dataset(filepath) as dfile:\n",
    "    PT_vars_Train = np.array(dfile['PT_vars_Train'])\n",
    "    NWP_time_Train = dfile['init_time']\n",
    "    print(NWP_time_Train)\n",
    "\n",
    "filepath = os.path.join(prefix,'GT_prep_Train.nc')\n",
    "with xr.open_dataset(filepath) as dfile:\n",
    "    GT_prep_Train = np.array(dfile['GT_prep_Train'])\n",
    "\n",
    "filepath = os.path.join(prefix,'PT_vars_Test.nc')\n",
    "with xr.open_dataset(filepath) as dfile:\n",
    "    PT_vars_Test = np.array(dfile['PT_vars_Test'])\n",
    "    NWP_time_Test = dfile['init_time']\n",
    "    print(NWP_time_Test)\n",
    "    lat = dfile['lat']\n",
    "    lon = dfile['lon']\n",
    "    n_lat = len(lat)\n",
    "    n_lon = len(lon)\n",
    "\n",
    "filepath = os.path.join(prefix,'GT_prep_Test.nc')\n",
    "with xr.open_dataset(filepath) as dfile:\n",
    "    GT_prep_Test = np.array(dfile['GT_prep_Test'])\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5926622d-3f92-4f90-9fc0-9180c92f2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model forecast\n",
    "NWP_fcst_ids = 28\n",
    "Mtest = copy.deepcopy(PT_vars_Test[:,:,:,NWP_fcst_ids:NWP_fcst_ids+1])\n",
    "Ytest = copy.deepcopy(GT_prep_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251cd53-8a82-4878-b514-0c2f407c8ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a433d2d-36b6-4ba2-afd1-355812ed10a9",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e0d3a2-4a98-4a64-aa11-6354ba9f4413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26892/800362520.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  array_nor = (array-array_min)/(array_max-array_min)\n",
      "/tmp/ipykernel_26892/800362520.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Xtest = (PT_vars_Test_temp-X_min)/(X_max-X_min)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# normalization  加0.01，取LOG,是的预报出来的值没有0\n",
    "def Scaler(k, array):\n",
    "    array[np.where(array<0)] = 0\n",
    "    return np.log(array+k)-np.log(k)\n",
    "\n",
    "def invScaler(k, array):    \n",
    "    return np.exp(array+np.log(k))-k\n",
    "\n",
    "def NormMaxMin(array,dim):\n",
    "    array_max = np.nanmax(array,dim)\n",
    "    array_min = np.nanmin(array,dim)\n",
    "    array_nor = (array-array_min)/(array_max-array_min)\n",
    "    return array_nor,array_max,array_min\n",
    "\n",
    "def invNormMaxMin(array_nor,array_max,array_min):\n",
    "    array = array_nor*(array_max-array_min)+array_min\n",
    "    return array\n",
    "\n",
    "def NormStd(array,dim):\n",
    "    array_mean = np.nanmean(array,dim)\n",
    "    array_std = np.nanstd(array,dim)\n",
    "    array_nor = (array-array_mean)/array_std\n",
    "    return array_nor,array_mean,array_std\n",
    "    \n",
    "def invNormStd(array_nor,array_mean,array_std):\n",
    "    array = array_nor*array_std+array_mean\n",
    "    return array \n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "# miss data\n",
    "def MissData(array):\n",
    "    array[np.where(np.isnan(array))] = 0\n",
    "    return array\n",
    "\n",
    "# negetive value\n",
    "def NegeData(array):\n",
    "    array[np.where(array<0)] = 0\n",
    "    return array\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "# preprocess\n",
    "def data_preprocessing(k,X,time_dim,geo_dim,prcp_dim,is_prcp,is_geos):\n",
    "    '''\n",
    "        X: the inputs to be preprocessed\n",
    "           could be predictors or predictands:[samples,lat,lon,vars]\n",
    "        time_dim: the dimension to be averaged\n",
    "        geo_dim: the number of geo-variables\n",
    "        is_prcp: whether use Scaler\n",
    "        is_geos: whether has geo-variables in predictors\n",
    "    '''\n",
    "    X = MissData(X)\n",
    "    if is_prcp:\n",
    "        X = Scaler(k,X)\n",
    "    else:\n",
    "        if prcp_dim>0:\n",
    "            X[:,:,:,prcp_dim] = Scaler(k,X[:,:,:,prcp_dim])\n",
    "        \n",
    "    if is_geos: \n",
    "        X_geos = X[:,:,:,-geo_dim:]\n",
    "        X_geos_nor = np.zeros(X_geos.shape)*np.nan\n",
    "        for ivar in range(geo_dim):\n",
    "            geo_max = np.nanmax(X_geos[:,:,:,ivar])\n",
    "            geo_min = np.nanmin(X_geos[:,:,:,ivar])\n",
    "            X_geos_nor[:,:,:,ivar] = (X_geos[:,:,:,ivar]-geo_min)/(geo_max-geo_min)\n",
    "        \n",
    "    # X = pad_to_shape(X) \n",
    "    \n",
    "    X,X_max,X_min = NormMaxMin(X,time_dim)\n",
    "    \n",
    "    if is_geos:\n",
    "        X[:,:,:,-geo_dim:] = X_geos_nor\n",
    "        \n",
    "    X = MissData(X)\n",
    "    return X,X_max,X_min\n",
    "\n",
    "# postprocess\n",
    "def data_postprocessing(k,X,X_max,X_min,is_prcp):\n",
    "    '''\n",
    "        only for precipitaiton variable\n",
    "    '''\n",
    "    X = invNormMaxMin(X,X_max,X_min)\n",
    "    # X = pred_to_rad(X)   \n",
    "    X = MissData(X)\n",
    "    if is_prcp:\n",
    "        X = invScaler(k,X)\n",
    "        X = NegeData(X)\n",
    "    return X\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "# data preprocessing\n",
    "geo_dim = 3\n",
    "k = 0.01\n",
    "Xtrain,X_max,X_min = data_preprocessing(k,PT_vars_Train,time_dim=0,geo_dim=geo_dim,prcp_dim=NWP_fcst_ids,is_prcp=False,is_geos=True)\n",
    "Ytrain,Y_max,Y_min = data_preprocessing(k,GT_prep_Train,time_dim=0,geo_dim=0,prcp_dim=0,is_prcp=True,is_geos=False)\n",
    "height,width,channels = Xtrain.shape[1],Xtrain.shape[2],Xtrain.shape[3]\n",
    "del PT_vars_Train,GT_prep_Train\n",
    "\n",
    "# test data preprocessing\n",
    "PT_vars_Test_temp = copy.deepcopy(PT_vars_Test)\n",
    "PT_vars_Test_temp[:,:,:,NWP_fcst_ids:NWP_fcst_ids+1] = Scaler(k, PT_vars_Test[:,:,:,NWP_fcst_ids:NWP_fcst_ids+1])\n",
    "Xtest = (PT_vars_Test_temp-X_min)/(X_max-X_min)\n",
    "num_test = Xtest.shape[0]\n",
    "Xtest[:,:,:,-geo_dim:] = Xtrain[:num_test,:,:,-geo_dim:]\n",
    "Xtest = MissData(Xtest)\n",
    "del PT_vars_Test,GT_prep_Test,PT_vars_Test_temp\n",
    "gc.collect()\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa60ae6-d46e-467c-a091-04a708afb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_prcp = Xtrain[:,:,:,NWP_fcst_ids:NWP_fcst_ids+1]\n",
    "Xtrain_max_prcp = X_max[:,:,NWP_fcst_ids:NWP_fcst_ids+1]\n",
    "Xtrain_min_prcp = X_min[:,:,NWP_fcst_ids:NWP_fcst_ids+1]\n",
    "Xtest_prcp = Xtest[:,:,:,NWP_fcst_ids:NWP_fcst_ids+1]\n",
    "channels_prcp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fcf185-ab7c-4a20-8967-2d6d90ea6ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fae4284-93a1-459f-bb3a-b8fc24b9528d",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6900927b-92a8-4ac5-b258-dcd6f82d5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_and_concate(down_layer, layer, data_format='channels_first'):\n",
    "    if data_format == 'channels_first':\n",
    "        in_channel = down_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    else:\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "\n",
    "    concate = my_concat([up, layer])\n",
    "\n",
    "    return concate\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n",
    "    if data_format == 'channels_first':\n",
    "        in_channel = down_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    else:\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "\n",
    "    concate = my_concat([up, layer])\n",
    "    return concate\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n",
    "    # theta_x(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
    "\n",
    "    # phi_g(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
    "\n",
    "    # f(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "    # psi_f(?,g_height,g_width,1)\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "    # rate(?,x_height,x_width)\n",
    "\n",
    "    # att_x(?,x_height,x_width,x_channel)\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
    "\n",
    "              padding='same', data_format='channels_first'):\n",
    "    if data_format == 'channels_first':\n",
    "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
    "\n",
    "    layer = input_layer\n",
    "    for i in range(2):\n",
    "        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
    "        if batch_normalization:\n",
    "            layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n",
    "        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
    "\n",
    "    if out_n_filters != input_n_filters:\n",
    "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
    "            input_layer)\n",
    "    else:\n",
    "        skip_layer = input_layer\n",
    "    out_layer = add([layer, skip_layer])\n",
    "    return out_layer\n",
    "\n",
    "def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
    "\n",
    "                  padding='same', data_format='channels_first'):\n",
    "    if data_format == 'channels_first':\n",
    "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
    "\n",
    "    if out_n_filters != input_n_filters:\n",
    "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
    "            input_layer)\n",
    "    else:\n",
    "        skip_layer = input_layer\n",
    "\n",
    "    layer = skip_layer\n",
    "    for j in range(2):\n",
    "\n",
    "        for i in range(2):\n",
    "            if i == 0:\n",
    "\n",
    "                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
    "                    layer)\n",
    "                if batch_normalization:\n",
    "                    layer1 = BatchNormalization()(layer1)\n",
    "                layer1 = Activation('relu')(layer1)\n",
    "            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
    "                add([layer1, layer]))\n",
    "            if batch_normalization:\n",
    "                layer1 = BatchNormalization()(layer1)\n",
    "            layer1 = Activation('relu')(layer1)\n",
    "        layer = layer1\n",
    "\n",
    "    out_layer = add([layer, skip_layer])\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed8c3e2-124e-4290-b539-ed7a424050a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_SHAPE = (height,width,channels_prcp)\n",
    "Output_SHAPE = (height,width,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c72e26-55f5-45ad-9474-78ef6257db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator.\n",
    "def generator_unet(n_label = 1, depth=4, features=64, \\\n",
    "                data_format='channels_last', mode='regression', name=''):\n",
    "    \n",
    "    inputs = Input(shape=Input_SHAPE)\n",
    "    x = inputs\n",
    "    skips = []\n",
    "    for i in range(depth):\n",
    "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "        skips.append(x)\n",
    "        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n",
    "        features = features * 2\n",
    "\n",
    "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "\n",
    "    for i in reversed(range(depth)):\n",
    "        features = features // 2\n",
    "        # attention_up_and_concate(x,[skips[i])\n",
    "        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n",
    "        # print('skips[{0}] shape is: {1}'.format(i, skips[i].shape))\n",
    "        # print('x shape is: {}'.format(x.shape))\n",
    "        x = concatenate([skips[i], x], axis=-1)\n",
    "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
    "\n",
    "    conv = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
    "    if mode == 'regression':\n",
    "        outputs = core.Activation('linear')(conv)\n",
    "    elif mode == 'segmentation':\n",
    "        outputs = core.Activation('sigmoid')(conv)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    # tf.summary.histogram('outputs',outputs)\n",
    "\n",
    "    return model, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3605a08a-e2eb-431e-a42b-94d3f5aca595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "def discriminator(depth=4, features=64, \\\n",
    "                data_format='channels_last', name=''):\n",
    "    inputs = Input(shape=Output_SHAPE)\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = Conv2D(features, (3, 3), (2, 2), activation='relu', padding='same', data_format=data_format)(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        # x = Dropout(0.25)(x)\n",
    "        features = features * 2\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x) \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c69f606-947d-4008-868a-435402b5cfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 09:29:58.221186: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-25 09:29:58.367641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.368898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.370072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.371234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.371298: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-25 09:29:58.429311: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-04-25 09:29:58.429395: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-04-25 09:29:58.446685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-25 09:29:58.460678: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-25 09:29:58.475878: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-04-25 09:29:58.489865: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-04-25 09:29:58.492507: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-04-25 09:29:58.501688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-04-25 09:29:58.905968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:61:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.907258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:62:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.908452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:89:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.909635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \n",
      "pciBusID: 0000:8a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-04-25 09:29:58.918559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2022-04-25 09:29:58.918659: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-04-25 09:30:00.536778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-25 09:30:00.536813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \n",
      "2022-04-25 09:30:00.536821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y Y Y \n",
      "2022-04-25 09:30:00.536828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N Y Y \n",
      "2022-04-25 09:30:00.536833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   Y Y N Y \n",
      "2022-04-25 09:30:00.536838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   Y Y Y N \n",
      "2022-04-25 09:30:00.547914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 31024 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)\n",
      "2022-04-25 09:30:00.551469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 31024 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)\n",
      "2022-04-25 09:30:00.552906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 31024 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0)\n",
      "2022-04-25 09:30:00.554336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 31024 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)\n",
      "2022-04-25 09:30:00.554662: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "g_model, g_out = generator_unet(depth=4, features=16)\n",
    "d_model, d_out = discriminator(depth=4, features=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae503d3-e424-452b-90de-11a4a1cf029c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92e3b643-7d2f-4885-9dbb-e71675730612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(keras.Model):\n",
    "    '''\n",
    "    reference: https://keras.io/examples/generative/wgan_gp/\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "        grid_lambda=20.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.grid_lambda = grid_lambda\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        fake_predictors, real_images = data\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            ### Get the latent vector\n",
    "            # random_latent_vectors = tf.random.normal(\n",
    "            #     shape=(batch_size, self.latent_dim)\n",
    "            # )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator(fake_predictors, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator(fake_predictors, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(real_img=real_logits, fake_img=gen_img_logits, \n",
    "                                   grid_lambda = self.grid_lambda)\n",
    "            \n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b233a1-be16-4b64-8d24-2503d7201366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, fake_predictors, num_img=6, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fake_predictors = fake_predictors\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(self.fake_predictors)\n",
    "\n",
    "        for i in range(self.num_img):\n",
    "            img = generated_images[i].numpy()\n",
    "            img = keras.preprocessing.image.array_to_img(img)\n",
    "            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c688019-dec1-4298-a6e3-2668911ab4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the optimizer for both networks\n",
    "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(real_img, fake_img, grid_lambda):\n",
    "    \"\"\"Grid cell regularizer.\n",
    "    Args:\n",
    "      generated_samples: Tensor of size [batch_size, h,w, 1].\n",
    "      batch_targets: Tensor of size [batch_size, h,w, 1].\n",
    "    Returns:\n",
    "      loss: A tensor of shape [batch_size].\n",
    "    \"\"\"\n",
    "    weights = tf.clip_by_value(real_img, 0.0, 24.0)\n",
    "    grid_cell_reg = tf.reduce_mean(tf.abs(fake_img - real_img) * weights)\n",
    "    return -tf.reduce_mean(fake_img) + grid_lambda * grid_cell_reg\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "NOISE_DIM = 128\n",
    "\n",
    "# # Instantiate the customer `GANMonitor` Keras callback.\n",
    "# cbk = GANMonitor(tf.Variable(Xtrain), num_img=3, latent_dim=NOISE_DIM)\n",
    "\n",
    "# Instantiate the WGAN model.\n",
    "wgan = WGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=NOISE_DIM,\n",
    "    discriminator_extra_steps=3,\n",
    "    grid_lambda = 1,\n",
    ")\n",
    "\n",
    "# Compile the WGAN model.\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ab6ec-bdce-40d1-b4bf-b07629c6aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "355/355 [==============================] - 24s 46ms/step - d_loss: 1042.0045 - g_loss: 426.7044\n",
      "Epoch 2/8\n",
      " 93/355 [======>.......................] - ETA: 11s - d_loss: 94.1263 - g_loss: 623.8875"
     ]
    }
   ],
   "source": [
    "# Start training the model.\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 8\n",
    "wgan.fit(Xtrain_prcp, Ytrain, \n",
    "         batch_size=BATCH_SIZE, epochs=EPOCHS) #, callbacks=[cbk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a121d123-26f2-4521-8de7-98bff90a4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_gen = wgan.generator\n",
    "Ftest_nor = trained_gen.predict(Xtest_prcp)\n",
    "Ftest = data_postprocessing(k,Ftest_nor,Y_max,Y_min,is_prcp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fdb6ab5-0673-469a-bb46-c760b3ca3068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of ref is 107.0\n",
      "max of fcst is 25.776393140631328\n",
      "rmse of fcst is 1.0429215234875673\n",
      "csi of fcst is [[3.97083863e-03]\n",
      " [9.22215007e-05]\n",
      " [0.00000000e+00]\n",
      " [0.00000000e+00]]\n",
      "evaluation costs 4.159373760223389 s\n"
     ]
    }
   ],
   "source": [
    "evalute_fcst(Ytest,Ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2c23399-8303-499a-ba0b-a59a67182def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(obs, sim):\n",
    "    obs = obs.flatten()\n",
    "    sim = sim.flatten()\n",
    "\n",
    "    return np.sqrt(np.nanmean((obs - sim) ** 2))\n",
    "\n",
    "def prep_clf(obs, sim, threshold=0.1):\n",
    "\n",
    "    obs = np.where(obs >= threshold, 1, 0)\n",
    "    sim = np.where(sim >= threshold, 1, 0)\n",
    "\n",
    "    # True positive (TP)\n",
    "    hits = np.sum((obs == 1) & (sim == 1))\n",
    "\n",
    "    # False negative (FN)\n",
    "    misses = np.sum((obs == 1) & (sim == 0))\n",
    "\n",
    "    # False positive (FP)\n",
    "    falsealarms = np.sum((obs == 0) & (sim == 1))\n",
    "\n",
    "    # True negative (TN)\n",
    "    correctnegatives = np.sum((obs == 0) & (sim == 0))\n",
    "\n",
    "    return hits, misses, falsealarms, correctnegatives\n",
    "\n",
    "def CSI(obs, sim, threshold=0.1):\n",
    "    \"\"\"\n",
    "    CSI - critical success index\n",
    "    details in the paper:\n",
    "    Woo, W., & Wong, W. (2017).\n",
    "    Operational Application of Optical Flow Techniques to Radar-Based\n",
    "    Rainfall Nowcasting.\n",
    "    Atmosphere, 8(3), 48. https://doi.org/10.3390/atmos8030048\n",
    "    Args:\n",
    "        obs (numpy.ndarray): observations\n",
    "        sim (numpy.ndarray): simulations\n",
    "        threshold (float)  : threshold for rainfall values binaryzation\n",
    "                             (rain/no rain)\n",
    "    Returns:\n",
    "        float: CSI value\n",
    "    \"\"\"\n",
    "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
    "                                                           threshold=threshold)\n",
    "\n",
    "    if (hits + misses + falsealarms)!=0:\n",
    "        return hits / (hits + misses + falsealarms)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def FAR(obs, sim, threshold=0.1):\n",
    "    '''\n",
    "    FAR - false alarm rate\n",
    "    details in the paper:\n",
    "    Woo, W., & Wong, W. (2017).\n",
    "    Operational Application of Optical Flow Techniques to Radar-Based\n",
    "    Rainfall Nowcasting.\n",
    "    Atmosphere, 8(3), 48. https://doi.org/10.3390/atmos8030048\n",
    "    Args:\n",
    "        obs (numpy.ndarray): observations\n",
    "        sim (numpy.ndarray): simulations\n",
    "        threshold (float)  : threshold for rainfall values binaryzation\n",
    "                             (rain/no rain)\n",
    "    Returns:\n",
    "        float: FAR value\n",
    "    '''\n",
    "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
    "                                                           threshold=threshold)\n",
    "    if (hits + falsealarms)!=0:\n",
    "        return falsealarms / (hits + falsealarms)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def POD(obs, sim, threshold=0.1):\n",
    "    '''\n",
    "    POD - probability of detection\n",
    "    details in the paper:\n",
    "    Woo, W., & Wong, W. (2017).\n",
    "    Operational Application of Optical Flow Techniques to Radar-Based\n",
    "    Rainfall Nowcasting.\n",
    "    Atmosphere, 8(3), 48. https://doi.org/10.3390/atmos8030048\n",
    "    Args:\n",
    "        obs (numpy.ndarray): observations\n",
    "        sim (numpy.ndarray): simulations\n",
    "        threshold (float)  : threshold for rainfall values binaryzation\n",
    "                             (rain/no rain)\n",
    "    Returns:\n",
    "        float: POD value\n",
    "    '''\n",
    "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
    "                                                           threshold=threshold)\n",
    "    if (hits + misses)!=0:\n",
    "        return hits / (hits + misses)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def ETS(obs, sim, threshold=0.1):\n",
    "    '''\n",
    "    ETS - Equitable Threat Score\n",
    "    details in the paper:\n",
    "    Winterrath, T., & Rosenow, W. (2007). A new module for the tracking of\n",
    "    radar-derived precipitation with model-derived winds.\n",
    "    Advances in Geosciences,10, 77–83. https://doi.org/10.5194/adgeo-10-77-2007\n",
    "\n",
    "    Args:\n",
    "        obs (numpy.ndarray): observations\n",
    "        sim (numpy.ndarray): simulations\n",
    "        threshold (float)  : threshold for rainfall values binaryzation\n",
    "                             (rain/no rain)\n",
    "    Returns:\n",
    "        float: ETS value\n",
    "    '''\n",
    "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
    "                                                           threshold=threshold)\n",
    "    num = (hits + falsealarms) * (hits + misses)\n",
    "    den = hits + misses + falsealarms + correctnegatives\n",
    "    Dr = num / den\n",
    "\n",
    "    if (hits + misses + falsealarms - Dr) != 0 :\n",
    "        ETS = (hits - Dr) / (hits + misses + falsealarms - Dr)\n",
    "    else:\n",
    "        ETS = np.nan\n",
    "    return ETS\n",
    "    \n",
    "def FSS(ref,fcst,TTT,R):\n",
    "    '''\n",
    "    compute FSS\n",
    "    param ref: observation\n",
    "    param fcst: forecast\n",
    "    param R: influence radius\n",
    "    param TTT: rain amount threshold, units:(m)\n",
    "    the shape of input should be: [num_sample,lat,lon]  \n",
    "    # here for a single file\n",
    "    '''\n",
    "    n_tim, n_lat, n_lon = ref.shape[0], ref.shape[1], ref.shape[2]\n",
    "    ref_p = np.ones([n_lat, n_lon])*np.nan\n",
    "    fcst_p = np.ones([n_lat, n_lon])*np.nan\n",
    "    fbs = np.ones([n_tim])*np.nan\n",
    "    fbs_worst = np.ones([n_tim])*np.nan\n",
    "    for t in range(n_tim):\n",
    "        print('>>>>>>>>>>>>>>>>>>>> {}'.format(t))\n",
    "        for i in range(n_lat):\n",
    "            for j in range(n_lon):            \n",
    "                if ~np.isnan(ref[0,i,j]):\n",
    "                    ref_box = ref[t,np.max([0,i-R]):np.min([n_lat,i+R+1]),np.max([0,j-R]):np.min([n_lon,j+R+1])]\n",
    "                    fcst_box = fcst[t,np.max([0,i-R]):np.min([n_lat,i+R+1]),np.max([0,j-R]):np.min([n_lon,j+R+1])]\n",
    "                    ref_p[i,j] = np.array(ref_box)[np.array(ref_box)>=TTT].size / (ref_box.size)\n",
    "                    fcst_p[i,j] = np.array(fcst_box)[np.array(fcst_box)>=TTT].size / (ref_box.size)         \n",
    "\n",
    "        fbs[t] = np.nanmean((ref_p-fcst_p)**2)\n",
    "        fbs_worst[t] = np.nanmean(ref_p**2) + np.nanmean(fcst_p**2)\n",
    "    fss = 1-np.nanmean(fbs)/np.nanmean(fbs_worst)\n",
    "    return fss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40b9649d-ef20-4c0a-af97-9a870be104e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_fcst(ref,fcst):\n",
    "    time0 = time.time()\n",
    "    print('max of ref is {}'.format(np.nanmax(ref)))\n",
    "    print('max of fcst is {}'.format(np.nanmax(fcst)))\n",
    "\n",
    "    rmse = RMSE(ref,fcst)\n",
    "    print('rmse of fcst is {}'.format(rmse))\n",
    "\n",
    "    csi_fcst = np.ones([4,1])*np.nan\n",
    "    csi_fcst[0] = CSI(ref,fcst,0.1)\n",
    "    csi_fcst[1] = CSI(ref,fcst,5)\n",
    "    csi_fcst[2] = CSI(ref,fcst,10)\n",
    "    csi_fcst[3] = CSI(ref,fcst,20)\n",
    "    print('csi of fcst is {}'.format(csi_fcst))\n",
    "\n",
    "    # fss_fcst = FSS(ref,fcst,20,3)\n",
    "    # print('fss of fcst is {}'.format(fss_fcst))\n",
    "\n",
    "    print('evaluation costs {} s'.format(time.time()-time0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e261d92-cb8f-4b49-97e8-a5f8933a6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max of ref is 107.0\n",
      "max of fcst is 3.1851418458863976\n",
      "rmse of fcst is 1.0392236644254458\n",
      "csi of fcst is [[0.00700247]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "evaluation costs 4.0153467655181885 s\n"
     ]
    }
   ],
   "source": [
    "evalute_fcst(Ytest,Ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be96af1-9466-49fe-b54b-6a07e540881a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
