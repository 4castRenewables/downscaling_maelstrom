{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dutch-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting climetlab\n",
      "  Downloading climetlab-0.11.9.tar.gz (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting climetlab_maelstrom_downscaling\n",
      "  Downloading climetlab_maelstrom_downscaling-0.1.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy in /p/software/hdfml/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (1.18.5)\n",
      "Requirement already satisfied: pandas in /p/software/hdfml/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (1.1.3)\n",
      "Collecting xarray>=0.19.0\n",
      "  Downloading xarray-2022.3.0-py3-none-any.whl (870 kB)\n",
      "\u001b[K     |████████████████████████████████| 870 kB 45.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/requests-2.24.0-py3.8.egg (from climetlab) (2.24.0)\n",
      "Requirement already satisfied: dask in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (2.30.0)\n",
      "Requirement already satisfied: netcdf4 in /p/software/hdfml/stages/2020/software/netcdf4-python/1.5.4-GCCcore-9.3.0-serial-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (1.5.4)\n",
      "Collecting cfgrib>=0.9.10\n",
      "  Downloading cfgrib-0.9.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cdsapi\n",
      "  Downloading cdsapi-0.5.1.tar.gz (12 kB)\n",
      "Collecting ecmwf-api-client>=1.6.1\n",
      "  Downloading ecmwf-api-client-1.6.3.tar.gz (12 kB)\n",
      "Collecting multiurl>=0.0.15\n",
      "  Downloading multiurl-0.0.15.tar.gz (16 kB)\n",
      "Collecting ecmwf-opendata\n",
      "  Downloading ecmwf-opendata-0.1.1.tar.gz (22 kB)\n",
      "Requirement already satisfied: tqdm in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (4.56.0)\n",
      "Collecting eccodes>=1.3.0\n",
      "  Downloading eccodes-1.4.2.tar.gz (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: magics>=1.5.6 in /p/home/jusers/langguth1/hdfml/.local/lib/python3.8/site-packages (from climetlab) (1.5.6)\n",
      "Collecting ecmwflibs\n",
      "  Downloading ecmwflibs-0.4.13-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (73.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 73.5 MB 384 kB/s  eta 0:00:01█████████   | 66.5 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pdbufr in /p/home/jusers/langguth1/hdfml/.local/lib/python3.8/site-packages (from climetlab) (0.9.0)\n",
      "Requirement already satisfied: pyodc in /p/home/jusers/langguth1/hdfml/.local/lib/python3.8/site-packages (from climetlab) (1.1.1)\n",
      "Requirement already satisfied: toolz in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/toolz-0.10.0-py3.8.egg (from climetlab) (0.10.0)\n",
      "Requirement already satisfied: filelock in /p/home/jusers/langguth1/hdfml/.local/lib/python3.8/site-packages (from climetlab) (3.3.1)\n",
      "Requirement already satisfied: pyyaml in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages (from climetlab) (5.3.1)\n",
      "Requirement already satisfied: markdown in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (3.2.2)\n",
      "Requirement already satisfied: termcolor in /p/software/hdfml/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (1.1.0)\n",
      "Requirement already satisfied: entrypoints in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (0.3)\n",
      "Requirement already satisfied: branca==0.3.1 in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from climetlab) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/python_dateutil-2.8.1-py3.8.egg (from pandas->climetlab) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/pytz-2020.1-py3.8.egg (from pandas->climetlab) (2020.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/packaging-20.4-py3.8.egg (from xarray>=0.19.0->climetlab) (20.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/chardet-3.0.4-py3.8.egg (from requests->climetlab) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/idna-2.10-py3.8.egg (from requests->climetlab) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/urllib3-1.25.10-py3.8.egg (from requests->climetlab) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/certifi-2020.6.20-py3.8.egg (from requests->climetlab) (2020.6.20)\n",
      "Requirement already satisfied: cftime in /p/software/hdfml/stages/2020/software/Jupyter/2020.2.6-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages (from netcdf4->climetlab) (1.2.1)\n",
      "Requirement already satisfied: attrs>=19.2 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/attrs-19.3.0-py3.8.egg (from cfgrib>=0.9.10->climetlab) (19.3.0)\n",
      "Requirement already satisfied: click in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/click-7.1.2-py3.8.egg (from cfgrib>=0.9.10->climetlab) (7.1.2)\n",
      "Requirement already satisfied: cffi in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/cffi-1.14.1-py3.8-linux-x86_64.egg (from eccodes>=1.3.0->climetlab) (1.14.1)\n",
      "Requirement already satisfied: findlibs in /p/home/jusers/langguth1/hdfml/.local/lib/python3.8/site-packages (from eccodes>=1.3.0->climetlab) (0.0.2)\n",
      "Requirement already satisfied: six in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/six-1.15.0-py3.8.egg (from branca==0.3.1->climetlab) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/Jinja2-2.11.2-py3.8.egg (from branca==0.3.1->climetlab) (2.11.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/pyparsing-2.4.7-py3.8.egg (from packaging>=20.0->xarray>=0.19.0->climetlab) (2.4.7)\n",
      "Requirement already satisfied: pycparser in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages (from cffi->eccodes>=1.3.0->climetlab) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /p/software/hdfml/stages/2020/software/Python/3.8.5-GCCcore-9.3.0/lib/python3.8/site-packages/MarkupSafe-1.1.1-py3.8-linux-x86_64.egg (from jinja2->branca==0.3.1->climetlab) (1.1.1)\n",
      "Building wheels for collected packages: climetlab, cdsapi, ecmwf-api-client, multiurl, ecmwf-opendata, eccodes\n",
      "  Building wheel for climetlab (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for climetlab: filename=climetlab-0.11.9-py3-none-any.whl size=210139 sha256=35797e979822a08d0df6f28fa8af8a8df91c343c1618032ef41834e1cc569b2b\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/2d/23/8b/ee27a319d429b1f68a7a3837833ac83dd2e75fd1b2e3dfc377\n",
      "  Building wheel for cdsapi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cdsapi: filename=cdsapi-0.5.1-py2.py3-none-any.whl size=11689 sha256=745376347120345284f26a24f555b8fa2be9508c97f6262403aa7c6a392cef85\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/5b/a2/af/7a52b8437e534f0b5f1b71232dd9534920579a142d9a191a63\n",
      "  Building wheel for ecmwf-api-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ecmwf-api-client: filename=ecmwf_api_client-1.6.3-py3-none-any.whl size=13517 sha256=64d5188724ee1a1e139b939d6503be5a1a2996c3b58b73c400e6153bed0f0777\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/a3/51/75/1fb8d90e50eff63ba17a457d09c14bf652c98f10a5eeae9ed8\n",
      "  Building wheel for multiurl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multiurl: filename=multiurl-0.0.15-py3-none-any.whl size=20907 sha256=bdc27c4ce9da1ea3121198a5ff97703735906a10e0ab602808d7db4af55b0778\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/3a/6e/5f/c5b7525e8b077926633b97e152c5020196277e240d4cedba25\n",
      "  Building wheel for ecmwf-opendata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ecmwf-opendata: filename=ecmwf_opendata-0.1.1-py3-none-any.whl size=19506 sha256=032729f8b657cae33304fb526665dc69e52ae7daef9fefe419acab7145fb6812\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/8d/2f/af/1c88ba214ec0327f088e540b71d0db3d7359e1153e239ce2a9\n",
      "  Building wheel for eccodes (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for eccodes: filename=eccodes-1.4.2-py3-none-any.whl size=39802 sha256=653dafa6f5f53286824c3837ea287b08e44165f38e4ba2bbf5e741d10140dabc\n",
      "  Stored in directory: /p/home/jusers/langguth1/hdfml/.cache/pip/wheels/18/6d/ad/e9d1417447ef708e31977ce463f4fde6740b96067ca773bb00\n",
      "Successfully built climetlab cdsapi ecmwf-api-client multiurl ecmwf-opendata eccodes\n",
      "Installing collected packages: xarray, eccodes, cfgrib, cdsapi, ecmwf-api-client, multiurl, ecmwf-opendata, ecmwflibs, climetlab, climetlab-maelstrom-downscaling\n",
      "\u001b[33m  WARNING: The script cfgrib is installed in '/p/home/jusers/langguth1/hdfml/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script climetlab is installed in '/p/home/jusers/langguth1/hdfml/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed cdsapi-0.5.1 cfgrib-0.9.10.1 climetlab-0.11.9 climetlab-maelstrom-downscaling-0.1.1 eccodes-1.4.2 ecmwf-api-client-1.6.3 ecmwf-opendata-0.1.1 ecmwflibs-0.4.13 multiurl-0.0.15 xarray-2022.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install climetlab climetlab_maelstrom_downscaling\n",
    "\n",
    "import climetlab as cml\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing \n",
    "import numpy as np\n",
    "#!pip install climetlab climetlab_maelstrom_downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Input, Concatenate,Conv3D,LeakyReLU, Dense, Conv2D,Activation, BatchNormalization,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D,Concatenate,Reshape)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import sigmoid, linear\n",
    "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
    "import tensorflow as tf\n",
    "#import tensorflow.python.ops.numpy_ops.np_config as np_config\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "#np_config.enable_numpy_behavior()\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.utils as ku\n",
    "from typing import Protocol\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "severe-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By downloading data from this dataset, you agree to the terms and conditions defined at https://git.ecmwf.int/projects/MLFET/repos/maelstrom-downscaling-ap5/browse/climetlab-maelstrom-downscaling-ap5/LICENSEIf you do not agree with such terms, do not download the data. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201607.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201605.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201604.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201606.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201608.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201705.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201609.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201704.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201706.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201707.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201708.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201709.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201804.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201805.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201806.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201807.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201808.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201809.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201904.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201905.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201906.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201907.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201909.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_201908.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202005.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202007.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202008.nc:   0%|          | 0.00/23.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202009.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202006.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet_ds_t2m_202004.nc:   0%|          | 0.00/22.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmlds_train = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"training\")\n",
    "cmlds_val = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"validation\")\n",
    "cmlds_test = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"testing\")\n",
    "#ds_train.to_netcdf(\"ds_train.nc\")\n",
    "#ds_val.to_netcdf(\"ds_val.nc\")\n",
    "#ds_test.to_netcdf(\"ds_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifteen-homeless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'stack-0dd409c3e18c220a7c3b4f95606832aa' (variables: 4, time: 1464, lat: 96, lon: 128)>\n",
      "dask.array<stack, shape=(4, 1464, 96, 128), dtype=float64, chunksize=(1, 62, 96, 128), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2016-04-01 ... 2019-09-30T12:00:00\n",
      "  * lon        (lon) float64 4.0 4.1 4.2 4.3 4.4 ... 16.3 16.4 16.5 16.6 16.7\n",
      "  * lat        (lat) float64 54.5 54.4 54.3 54.2 54.1 ... 45.3 45.2 45.1 45.0\n",
      "  * variables  (variables) <U7 't2m_in' 'z_in' 'z_tar' 't2m_tar'\n",
      "Attributes:\n",
      "    CDI:                        Climate Data Interface version 1.9.8 (https:/...\n",
      "    Conventions:                CF-1.6\n",
      "    history:                    Mon Aug 02 21:00:13 2021: cdo mergetime 2016/...\n",
      "    NCO:                        netCDF Operators version 4.9.5 (Homepage = ht...\n",
      "    history_of_appended_files:  Mon Aug  2 20:54:16 2021: Appended file /p/sc...\n",
      "    CDO:                        Climate Data Operators version 1.9.8 (https:/...\n"
     ]
    }
   ],
   "source": [
    "ds_train = cmlds_train.to_xarray()\n",
    "ds_val = cmlds_val.to_xarray()\n",
    "ds_test = cmlds_test.to_xarray()\n",
    "\n",
    "ds_test = ds_train.to_array(dim=\"variables\")\n",
    "print(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds_train = xr.open_dataset(\"ds_train.nc\")\n",
    "ds_val = xr.open_dataset(\"ds_val.nc\")\n",
    "ds_test = xr.open_dataset(\"ds_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "checked-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [pd.to_datetime(i).month for i in ds_train[\"time\"].values]\n",
    "times_val = [pd.to_datetime(i).month for i in ds_val[\"time\"].values]\n",
    "times_test = [pd.to_datetime(i).month for i in ds_test[\"time\"].values]\n",
    "times_val = np.array(times_val).reshape((len(times_val), 1))\n",
    "times_test= np.array(times_test).reshape((len(times_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consecutive-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One_Hot_Encode Categorical Data\n",
    "#get the month values\n",
    "#Bing: you can also embed hour, year by replacing. '.month' to 'hour', 'year'\n",
    "times = [pd.to_datetime(i).month for i in ds_train[\"time\"].values]\n",
    "n_classes = len(list(set(times)))\n",
    "times = np.array(times).reshape((len(times), 1))\n",
    "le = preprocessing.OneHotEncoder()\n",
    "le.fit(times)\n",
    "embed_train = le.transform(times).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indie-grass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1464, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_val = le.transform(times_val).toarray()\n",
    "embed_test = le.transform(times_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(list(set(times)))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lasting-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reshape_ds(ds):\n",
    "    ds = ds.to_array(dim = \"variables\").squeeze()\n",
    "    ds = ds.transpose(..., \"variables\")\n",
    "    #ds = np.squeeze(ds.values)\n",
    "    #ds = np.transpose(ds, (1, 2, 3, 0))\n",
    "    return ds\n",
    "#ds_test = reshape_ds(ds_test)\n",
    "#ds_val = reshape_ds(ds_val)\n",
    "ds_train = reshape_ds(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "continental-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z_tar', 't2m_tar']\n",
      "<xarray.DataArray 'stack-0dd409c3e18c220a7c3b4f95606832aa' (time: 1464, lat: 96, lon: 128, variables: 2)>\n",
      "dask.array<getitem, shape=(1464, 96, 128, 2), dtype=float64, chunksize=(62, 96, 128, 1), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2016-04-01 ... 2019-09-30T12:00:00\n",
      "  * lon        (lon) float64 4.0 4.1 4.2 4.3 4.4 ... 16.3 16.4 16.5 16.6 16.7\n",
      "  * lat        (lat) float64 54.5 54.4 54.3 54.2 54.1 ... 45.3 45.2 45.1 45.0\n",
      "  * variables  (variables) <U7 't2m_in' 'z_in'\n",
      "Attributes:\n",
      "    CDI:                        Climate Data Interface version 1.9.8 (https:/...\n",
      "    Conventions:                CF-1.6\n",
      "    history:                    Mon Aug 02 21:00:13 2021: cdo mergetime 2016/...\n",
      "    NCO:                        netCDF Operators version 4.9.5 (Homepage = ht...\n",
      "    history_of_appended_files:  Mon Aug  2 20:54:16 2021: Appended file /p/sc...\n",
      "    CDO:                        Climate Data Operators version 1.9.8 (https:/...\n"
     ]
    }
   ],
   "source": [
    "all_vars = list(ds_train[\"variables\"].values)\n",
    "\n",
    "invars = [var for var in all_vars if var.endswith(\"_in\")]\n",
    "tarvars = [var for var in all_vars if var.endswith(\"_tar\")]\n",
    "\n",
    "print(tarvars)\n",
    "\n",
    "print(ds_train.sel(variables=slice(*invars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "earned-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((ds_train.sel(variables=slice(*invars)), ds_train.sel(variables=slice(*tarvars))))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(100).repeat(1).batch(2)\n",
    "train_dataset = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "irish-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 2.80570588e+02 -5.05680624e-02]\n",
      "   [ 2.80570000e+02 -6.26187835e-02]\n",
      "   [ 2.80569412e+02 -7.46695046e-02]\n",
      "   ...\n",
      "   [ 2.81227446e+02  4.07008704e+02]\n",
      "   [ 2.81287377e+02  4.41981485e+02]\n",
      "   [ 2.81347307e+02  4.76954267e+02]]\n",
      "\n",
      "  [[ 2.80542645e+02 -1.04135515e-02]\n",
      "   [ 2.80544412e+02 -3.44283797e-02]\n",
      "   [ 2.80546180e+02 -5.84432080e-02]\n",
      "   ...\n",
      "   [ 2.81629946e+02  5.16124493e+02]\n",
      "   [ 2.81691281e+02  5.57755050e+02]\n",
      "   [ 2.81752616e+02  5.99385608e+02]]\n",
      "\n",
      "  [[ 2.80514701e+02  2.97409594e-02]\n",
      "   [ 2.80518824e+02 -6.23797598e-03]\n",
      "   [ 2.80522947e+02 -4.22169114e-02]\n",
      "   ...\n",
      "   [ 2.82032447e+02  6.25240282e+02]\n",
      "   [ 2.82095185e+02  6.73528615e+02]\n",
      "   [ 2.82157924e+02  7.21816948e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.88471577e+02  7.71648538e+03]\n",
      "   [ 2.88798092e+02  7.56003957e+03]\n",
      "   [ 2.89124607e+02  7.40359376e+03]\n",
      "   ...\n",
      "   [ 2.90590049e+02  2.41960971e+03]\n",
      "   [ 2.90526794e+02  2.42392748e+03]\n",
      "   [ 2.90463539e+02  2.42824526e+03]]\n",
      "\n",
      "  [[ 2.88291674e+02  7.60331395e+03]\n",
      "   [ 2.88657876e+02  7.37779515e+03]\n",
      "   [ 2.89024077e+02  7.15227635e+03]\n",
      "   ...\n",
      "   [ 2.90347075e+02  3.12258000e+03]\n",
      "   [ 2.90287875e+02  3.10891535e+03]\n",
      "   [ 2.90228675e+02  3.09525070e+03]]\n",
      "\n",
      "  [[ 2.88111771e+02  7.49014251e+03]\n",
      "   [ 2.88517660e+02  7.19555073e+03]\n",
      "   [ 2.88923548e+02  6.90095895e+03]\n",
      "   ...\n",
      "   [ 2.90104101e+02  3.82555030e+03]\n",
      "   [ 2.90048957e+02  3.79390322e+03]\n",
      "   [ 2.89993812e+02  3.76225613e+03]]]\n",
      "\n",
      "\n",
      " [[[ 2.85202976e+02 -5.05680624e-02]\n",
      "   [ 2.85230490e+02 -6.26187835e-02]\n",
      "   [ 2.85258005e+02 -7.46695046e-02]\n",
      "   ...\n",
      "   [ 2.87648695e+02  4.07008704e+02]\n",
      "   [ 2.87806377e+02  4.41981485e+02]\n",
      "   [ 2.87964060e+02  4.76954267e+02]]\n",
      "\n",
      "  [[ 2.85250759e+02 -1.04135515e-02]\n",
      "   [ 2.85282835e+02 -3.44283797e-02]\n",
      "   [ 2.85314910e+02 -5.84432080e-02]\n",
      "   ...\n",
      "   [ 2.88360062e+02  5.16124493e+02]\n",
      "   [ 2.88510806e+02  5.57755050e+02]\n",
      "   [ 2.88661550e+02  5.99385608e+02]]\n",
      "\n",
      "  [[ 2.85298543e+02  2.97409594e-02]\n",
      "   [ 2.85335179e+02 -6.23797598e-03]\n",
      "   [ 2.85371815e+02 -4.22169114e-02]\n",
      "   ...\n",
      "   [ 2.89071429e+02  6.25240282e+02]\n",
      "   [ 2.89215235e+02  6.73528615e+02]\n",
      "   [ 2.89359040e+02  7.21816948e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.94818461e+02  7.71648538e+03]\n",
      "   [ 2.94747632e+02  7.56003957e+03]\n",
      "   [ 2.94676804e+02  7.40359376e+03]\n",
      "   ...\n",
      "   [ 2.93930521e+02  2.41960971e+03]\n",
      "   [ 2.93939008e+02  2.42392748e+03]\n",
      "   [ 2.93947494e+02  2.42824526e+03]]\n",
      "\n",
      "  [[ 2.94655101e+02  7.60331395e+03]\n",
      "   [ 2.94632278e+02  7.37779515e+03]\n",
      "   [ 2.94609454e+02  7.15227635e+03]\n",
      "   ...\n",
      "   [ 2.93377300e+02  3.12258000e+03]\n",
      "   [ 2.93393550e+02  3.10891535e+03]\n",
      "   [ 2.93409799e+02  3.09525070e+03]]\n",
      "\n",
      "  [[ 2.94491741e+02  7.49014251e+03]\n",
      "   [ 2.94516923e+02  7.19555073e+03]\n",
      "   [ 2.94542104e+02  6.90095895e+03]\n",
      "   ...\n",
      "   [ 2.92824078e+02  3.82555030e+03]\n",
      "   [ 2.92848091e+02  3.79390322e+03]\n",
      "   [ 2.92872104e+02  3.76225613e+03]]]], shape=(2, 96, 128, 2), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[[-3.51814885e+00  2.80534443e+02]\n",
      "   [-3.98937708e+00  2.80514822e+02]\n",
      "   [-3.98937708e+00  2.80487605e+02]\n",
      "   ...\n",
      "   [ 7.23495972e+01  2.80816738e+02]\n",
      "   [ 1.18058736e+02  2.81616785e+02]\n",
      "   [ 1.58113136e+02  2.81856672e+02]]\n",
      "\n",
      "  [[ 2.60781822e+00  2.80461654e+02]\n",
      "   [ 2.60781822e+00  2.80455325e+02]\n",
      "   [ 3.07904646e+00  2.80442033e+02]\n",
      "   ...\n",
      "   [ 1.94868939e+02  2.81695903e+02]\n",
      "   [ 2.64610718e+02  2.81879458e+02]\n",
      "   [ 3.15974595e+02  2.81995921e+02]]\n",
      "\n",
      "  [[-3.51814885e+00  2.80375573e+02]\n",
      "   [-6.90779430e-01  2.80374307e+02]\n",
      "   [ 4.02150293e+00  2.80372408e+02]\n",
      "   ...\n",
      "   [ 3.99381993e+02  2.81995921e+02]\n",
      "   [ 4.86559217e+02  2.82092129e+02]\n",
      "   [ 5.53944855e+02  2.82182008e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 7.37732971e+03  2.88655803e+02]\n",
      "   [ 7.20250404e+03  2.89355844e+02]\n",
      "   [ 8.01961380e+03  2.88885564e+02]\n",
      "   ...\n",
      "   [ 2.29277705e+03  2.90447047e+02]\n",
      "   [ 1.75840423e+03  2.90938215e+02]\n",
      "   [ 1.50017115e+03  2.91233802e+02]]\n",
      "\n",
      "  [[ 7.92583938e+03  2.88219069e+02]\n",
      "   [ 8.70525088e+03  2.88256413e+02]\n",
      "   [ 1.00147942e+04  2.87405098e+02]\n",
      "   ...\n",
      "   [ 2.31068372e+03  2.90564143e+02]\n",
      "   [ 2.21973667e+03  2.90773016e+02]\n",
      "   [ 2.38560901e+03  2.90755293e+02]]\n",
      "\n",
      "  [[ 9.41680552e+03  2.86932285e+02]\n",
      "   [ 1.04153382e+04  2.86612646e+02]\n",
      "   [ 1.13912518e+04  2.85942987e+02]\n",
      "   ...\n",
      "   [ 2.16978648e+03  2.90809094e+02]\n",
      "   [ 2.20842719e+03  2.90658452e+02]\n",
      "   [ 2.34037110e+03  2.90647692e+02]]]\n",
      "\n",
      "\n",
      " [[[-3.51814885e+00  2.85146015e+02]\n",
      "   [-3.98937708e+00  2.85155146e+02]\n",
      "   [-3.98937708e+00  2.85192889e+02]\n",
      "   ...\n",
      "   [ 7.23495972e+01  2.87675362e+02]\n",
      "   [ 1.18058736e+02  2.89676316e+02]\n",
      "   [ 1.58113136e+02  2.90386725e+02]]\n",
      "\n",
      "  [[ 2.60781822e+00  2.85176453e+02]\n",
      "   [ 2.60781822e+00  2.85189236e+02]\n",
      "   [ 3.07904646e+00  2.85211760e+02]\n",
      "   ...\n",
      "   [ 1.94868939e+02  2.90658835e+02]\n",
      "   [ 2.64610718e+02  2.91250538e+02]\n",
      "   [ 3.15974595e+02  2.91388723e+02]]\n",
      "\n",
      "  [[-3.51814885e+00  2.85222109e+02]\n",
      "   [-6.90779430e-01  2.85239154e+02]\n",
      "   [ 4.02150293e+00  2.85259242e+02]\n",
      "   ...\n",
      "   [ 3.99381993e+02  2.91055130e+02]\n",
      "   [ 4.86559217e+02  2.91248711e+02]\n",
      "   [ 5.53944855e+02  2.91347328e+02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 7.37732971e+03  2.96107127e+02]\n",
      "   [ 7.20250404e+03  2.96315928e+02]\n",
      "   [ 8.01961380e+03  2.95311494e+02]\n",
      "   ...\n",
      "   [ 2.29277705e+03  2.93596651e+02]\n",
      "   [ 1.75840423e+03  2.94059300e+02]\n",
      "   [ 1.50017115e+03  2.94416026e+02]]\n",
      "\n",
      "  [[ 7.92583938e+03  2.95653001e+02]\n",
      "   [ 8.70525088e+03  2.94835453e+02]\n",
      "   [ 1.00147942e+04  2.93256361e+02]\n",
      "   ...\n",
      "   [ 2.31068372e+03  2.93458466e+02]\n",
      "   [ 2.21973667e+03  2.93678224e+02]\n",
      "   [ 2.38560901e+03  2.93649004e+02]]\n",
      "\n",
      "  [[ 9.41680552e+03  2.93926593e+02]\n",
      "   [ 1.04153382e+04  2.92678660e+02]\n",
      "   [ 1.13912518e+04  2.91260278e+02]\n",
      "   ...\n",
      "   [ 2.16978648e+03  2.93639264e+02]\n",
      "   [ 2.20842719e+03  2.93661179e+02]\n",
      "   [ 2.34037110e+03  2.93690399e+02]]]], shape=(2, 96, 128, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(train_dataset)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = ds_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = ds_train.shape[1]\n",
    "H = ds_train.shape[2]\n",
    "C = ds_train.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [ds_train.shape[1],ds_train.shape[2], 2]\n",
    "target_shape = [ds_train.shape[1],ds_train.shape[2],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxiliary functions used for parsing the hyerparameters from hparams_dict\n",
    "def reduce_dict(dict_in: dict, dict_ref: dict):\n",
    "    \"\"\"\n",
    "    Reduces input dictionary to keys from reference dictionary. If the input dictionary lacks some keys, these are \n",
    "    copied over from the reference dictionary, i.e. the reference dictionary provides the defaults\n",
    "    :param dict_in: input dictionary\n",
    "    :param dict_ref: reference dictionary\n",
    "    :return: reduced form of input dictionary (with keys complemented from dict_ref if necessary)\n",
    "    \"\"\"\n",
    "    method = reduce_dict.__name__\n",
    "\n",
    "    # sanity checks\n",
    "    assert isinstance(dict_in, dict), \"%{0}: dict_in must be a dictionary, but is of type {1}\"\\\n",
    "                                      .format(method, type(dict_in))\n",
    "    assert isinstance(dict_ref, dict), \"%{0}: dict_ref must be a dictionary, but is of type {1}\"\\\n",
    "                                       .format(method, type(dict_ref)) \n",
    "\n",
    "    dict_merged = {**dict_ref, **dict_in}\n",
    "    dict_reduced = {key: dict_merged[key] for key in dict_ref}\n",
    "\n",
    "    return dict_reduced\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(inputs: tf.Tensor = None, num_filters: int = None, kernel: tuple = (3,3), padding: str=\"same\",\n",
    "              activation: str = \"relu\", kernel_init: str = \"he_normal\", l_batch_normalization: bool=False): \n",
    "\n",
    "    \"\"\"\n",
    "    A convolutional layer with optional batch normalization\n",
    "    :param inputs: the input data with dimensions nx, ny and nc\n",
    "    :param num_filters: number of filters (output channel dimension)\n",
    "    :param kernel: tuple indictating kernel size\n",
    "    :param padding: technique for padding (e.g. \"same\" or \"valid\")\n",
    "    :param activation: activation fuction for neurons (e.g. \"relu\")\n",
    "    :param kernel_init: initialization technique (e.g. \"he_normal\" or \"glorot_uniform\")\n",
    "    \"\"\"\n",
    "    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)\n",
    "    if l_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding=\"same\", activation=\"relu\", \n",
    "                     kernel_init=\"he_normal\", l_batch_normalization=False):\n",
    "    \"\"\"\n",
    "    Sequential application of two convolutional layers (using conv_block).\n",
    "    \"\"\"\n",
    "\n",
    "    x = conv_block(inputs, num_filters, kernel, padding, activation,\n",
    "                   kernel_init, l_batch_normalization)\n",
    "    \n",
    "    for i in np.arange(n-1):\n",
    "        x = conv_block(x, num_filters, kernel, padding, activation,\n",
    "                       kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, num_filters:int=None, kernel_maxpool: tuple=(2,2), l_large: bool=False):\n",
    "    \"\"\"\n",
    "    One complete encoder-block used in U-net\n",
    "    \"\"\"\n",
    "    if l_large:\n",
    "        x = conv_block_n(inputs, num_filters, n=2)\n",
    "    else:\n",
    "        x = conv_block(inputs, num_filters)\n",
    "\n",
    "    p = MaxPool2D(kernel_maxpool)(x)\n",
    "\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= \"same\",\n",
    "                  activation: str=\"relu\", kernel_init: str=\"he_normal\", l_batch_normalization: bool=False):\n",
    "    \"\"\"\n",
    "    One complete decoder block used in U-net (reverting the encoder)\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)\n",
    "    return x\n",
    "\n",
    "def generator(input_shape, embed_shape, channels_start=56, z_branch=False):\n",
    "    \"\"\"\n",
    "    Function to build up the generator architecture, here we take UNET as generator\n",
    "    \"\"\"\n",
    "\n",
    "   # embedding input\n",
    "    in_label = Input(shape=(embed_shape))\n",
    "\n",
    "    # linear multiplication\n",
    "    n_nodes = input_shape[0] * input_shape[1]* input_shape[2]\n",
    "    li = Dense(n_nodes)(in_label)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((input_shape[0], input_shape[1],input_shape[2]))(li)\n",
    "\n",
    "    #image generator \n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    #merge image gen and label input\n",
    "    merge = Concatenate()([inputs, li])\n",
    "\n",
    "    \"\"\" encoder \"\"\"\n",
    "    s1, e1 = encoder_block(merge, channels_start, l_large=True)\n",
    "    s2, e2 = encoder_block(e1, channels_start*2, l_large=False)\n",
    "    s3, e3 = encoder_block(e2, channels_start*4, l_large=False)\n",
    "\n",
    "    \"\"\" bridge encoder <-> decoder \"\"\"\n",
    "    b1 = conv_block(e3, channels_start*8)\n",
    "\n",
    "    \"\"\" decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, channels_start*4)\n",
    "    d2 = decoder_block(d1, s2, channels_start*2)\n",
    "    d3 = decoder_block(d2, s1, channels_start)\n",
    "\n",
    "    output_temp = Conv2D(1, (1,1), kernel_initializer=\"he_normal\", name=\"output_temp\")(d3)\n",
    "    if z_branch:\n",
    "        output_z = Conv2D(1, (1, 1), kernel_initializer=\"he_normal\", name=\"output_z\")(d3)\n",
    "\n",
    "        model = Model([inputs,in_label], [output_temp, output_z], name=\"t2m_downscaling_unet_with_z\")\n",
    "    else:    \n",
    "        model = Model([inputs, in_label], output_temp, name=\"t2m_downscaling_unet\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(target_shape):\n",
    "    \"\"\"\n",
    "    Discriminator: this discriminator so far perfoms best on the precipitation dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x = Input(target_shape)\n",
    "    conv1 = Conv2D(filters=4, kernel_size=2, strides=(1, 1), padding='same')(x)\n",
    "   \n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    conv2 = tf.reshape(conv1, [-1,1])\n",
    "    fc2 = LeakyReLU(0.2)(conv2)\n",
    "    out_logit = Dense(1)(fc2)\n",
    "    out = tf.nn.sigmoid(out_logit) \n",
    "    D = Model(x, out)\n",
    "    return D\n",
    "\n",
    "def ciritic(target_shape):\n",
    "    print(\"You are trainaing Wasserstain GAN\")\n",
    "    x = Input(target_shape)\n",
    "    conv1 = Conv3D(filters=4, kernel_size=2, strides=(1, 1,1), padding='same')(x)\n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    conv2 = tf.reshape(conv1, [-1,1])\n",
    "    fc2 = LeakyReLU(0.2)(conv2)\n",
    "    out = Dense(1, activiation=\"linear\")(fc2)\n",
    "    D = Model(x, out)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-shaft",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This chunk defines the losses\n",
    "from typing import Any, Callable\n",
    "### Vanilla GAN loss        \n",
    "def gan_gen_loss(D_fake):\n",
    "    \"\"\"\n",
    "    Define generator loss\n",
    "\n",
    "    Return:  the loss of generator given inputs\n",
    "    \"\"\"\n",
    "    real_labels = tf.ones_like(D_fake)\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=real_labels))            \n",
    "    return G_loss\n",
    "\n",
    "def gan_disc_loss(D_real, D_fake):\n",
    "    \"\"\"\n",
    "    Return the loss of discriminator (Vanilla GAN)\n",
    "    \"\"\"\n",
    "    real_labels = tf.ones_like(D_real)\n",
    "    gen_labels = tf.zeros_like(D_fake)\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real,\n",
    "                                                                          labels=real_labels))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake,\n",
    "                                                                          labels=gen_labels))\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    return D_loss\n",
    "\n",
    "def get_gan_loss(D_real, D_fake):\n",
    "    D_loss = gan_disc_loss(D_real, D_fake)\n",
    "    G_loss = gan_gen_loss(D_fake)\n",
    "    return D_loss, G_loss\n",
    "\n",
    "####WGAN loss\n",
    "def wgan_gen_loss(D_fake):\n",
    "    G_loss = -tf.reduce_mean(D_fake)\n",
    "    return G_loss\n",
    "\n",
    "def wgan_critic_loss(D_real,D_fake):\n",
    "    \"\"\"\n",
    "    Return the loss of critic (WGAN)\n",
    "    \"\"\"\n",
    "    D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "    return D_loss\n",
    "\n",
    "def get_wgan_losses(D_real, D_fake):\n",
    "    G_loss =  wgan_gen_loss(D_fake)\n",
    "    D_loss = wgan_critic_loss(D_real,D_fake)\n",
    "    return D_loss, G_loss\n",
    "\n",
    "## Reconstruction loss for generator (UNet)\n",
    "def get_recon_loss(target, gen_images):\n",
    "    \"\"\"\n",
    "    Get reconstruction loss \n",
    "    \"\"\"\n",
    "    recon_loss = tf.reduce_mean(tf.square(target - gen_images))\n",
    "    return recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-complement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your hparameters in a dictionary\n",
    "hparams_dict = {\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 0.001,\n",
    "    \"max_epochs\": 5,\n",
    "    \"context_frames\": 7,\n",
    "    \"sequence_length\": 15,\n",
    "    \"ngf\": 16,\n",
    "    \"enable_gan\": True, #enable gan\n",
    "    \"enable_wgan\":True, #enable wgan \n",
    "    \"enable_embed\":False,  #enable the conditional information \n",
    "    \"d_steps\": 5, # The original paper recommends training, the discriminator for `x` more steps (typically 5) as compared t # one step of the generator.\n",
    "    \"alpha\":0.00005, #WGAN hparams\n",
    "    \"clip_const\":0.01, # default WGAN hparams\n",
    "    \"weight_recon\":0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANModel(object):\n",
    "\n",
    "    def __init__(self, mode: str = \"train\", hparams_dict: dict = None, \n",
    "                 target_shape:list=None, input_shape:list=None,embed_shape:list=None,\n",
    "                 discriminator: Callable=None, generator:Callable=None): \n",
    "        \"\"\"\n",
    "         This is a class for building convLSTM GAN architecture by using updated hparameters\n",
    "             mode                  : string, either \"train\" or \"val\" \n",
    "             hparams_dict          : dictionary, contains the hyperparameters names and default values\n",
    "             input_shape           : tf.Tensor shape equal to the input shape\n",
    "        \"\"\"\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        self.target_shape = target_shape\n",
    "        self.embed_shape = embed_shape\n",
    "        #obtain the hyperparmeters\n",
    "        self.hparams_dict = hparams_dict\n",
    "        self.hparams = self.parse_hparams()\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.learning_rate = self.hparams.lr\n",
    "        self.max_epochs = self.hparams.max_epochs\n",
    "        self.sequence_length = self.hparams.sequence_length\n",
    "        self.context_frames = self.hparams.context_frames\n",
    "        self.loss_fun = self.hparams.loss_fun\n",
    "        self.enable_gan = self.hparams.enable_gan\n",
    "        self.enable_wgan = self.hparams.enable_wgan\n",
    "        self.enable_embed = self.hparams.enable_embed\n",
    "        self.d_steps = self.hparams.d_steps\n",
    "        self.ngf = self.hparams.ngf #latent dim\n",
    "        self.weight_recon = self.hparams.weight_recon\n",
    "        self.clip_const = self.hparams.clip_const\n",
    "        #Class attributes\n",
    "        self.recon_loss = None\n",
    "        self.G_loss = None\n",
    "        self.D_loss = None\n",
    "\n",
    "        \n",
    "\n",
    "    def hparams_check(self):\n",
    "        if not self.enable_gan:\n",
    "            if self.enable_wgan:\n",
    "                raise(\"You must set enable_gan to 'True' in hparams_dict congifuration\")\n",
    "\n",
    "                \n",
    "    def parse_hparams(self): \n",
    "        self.hparams_dict = dotdict(self.hparams_dict)\n",
    "        return self.hparams_dict\n",
    "\n",
    "    def define_optimizers(self):\n",
    "        self.d_optim = tf.keras.optimizers.Adam(self.learning_rate)\n",
    "        self.g_optim = tf.keras.optimizers.Adam(self.learning_rate)\n",
    "\n",
    "    def get_losses(self, D_real, D_fake, target, gen_image):\n",
    "        \"\"\"\n",
    "        Get the losses based on the adopted model (GAN, WGAN, or UNet)\n",
    "        \"\"\"\n",
    "        # Reconstruction loss\n",
    "        recon_loss = get_recon_loss(target,gen_image)\n",
    "\n",
    "        if self.enable_wgan:\n",
    "            G_loss, D_loss = get_wgan_losses(D_real, D_fake)\n",
    "        else:\n",
    "            #vanilla GAN\n",
    "             G_loss, D_loss = get_gan_losses(D_real, D_fake)\n",
    "\n",
    "        return G_loss, D_loss, recon_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, inputs, target, embed, i):\n",
    "        \"\"\"\n",
    "        Training model per step\n",
    "        inputs: inputs tensorflow\n",
    "        target: target tensor\n",
    "        embed: one hot embeding tensor\n",
    "        i: the training step\n",
    "        d_steps: the original paper recommends training, the discriminator for `x` more steps (typically 5) as compared t # one step of the generator.\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        \n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator.\n",
    "        \"\"\"\n",
    "\n",
    "        self.G = self.generator(self.input_shape, self.embed_shape)\n",
    "        self.D = self.discriminator(self.target_shape, self.embed_shape)\n",
    "        self.define_optimizers()\n",
    "\n",
    "        #Train discriminator/critic\n",
    "        for step in range(self.d_steps):\n",
    "            if self.enable_gan:\n",
    "                with tf.GradientTape() as d_tape:\n",
    "                    # Generate fake images given input images\n",
    "                    gen_images = self.G([inputs, embed])\n",
    "                    # Get the logits for the real images\n",
    "                    D_real = self.D(target)\n",
    "                    # Get the logits for the fake images\n",
    "                    D_fake = self.D(gen_images)\n",
    "                    # Calculate the discriminator loss using the fake and real image logits\n",
    "                    if self.enable_wgan:\n",
    "                        if i == 0 and step == 0 :\n",
    "                            print(\"You are training both generator and discriminator (WGAN)\")\n",
    "                            print(\"You are training {} times more discriminator/critic for one time generator\".format(self.d_steps))   \n",
    "                        D_loss = wgan_critic_loss(D_real,D_fake)\n",
    "                    else:\n",
    "                        if i == 0 and step == 0:\n",
    "                            print(\"You are training both generator and discriminator (GAN)\")\n",
    "                            print(\"You are training {} times more discriminator/critic for one time generator\".format(self.d_steps))   \n",
    "                        D_loss = gan_disc_loss(D_real, D_fake)\n",
    "\n",
    "                    d_gradients = d_tape.gradient(D_loss, self.D.trainable_variables)\n",
    "                    #define the training stratigy (ratio of number iteration of training on discriminator)\n",
    "                    self.d_optim.apply_gradients(zip(d_gradients, self.D.trainable_variables))\n",
    "            \n",
    "\n",
    "\n",
    "        # Train generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # Generate fake images given input images\n",
    "            gen_images = self.G([inputs,embed])\n",
    "            D_fake = self.D(gen_images)\n",
    "            G_loss = gan_gen_loss(D_fake)\n",
    "            recon_loss = get_recon_loss(target, gen_images)\n",
    "            total_gen_loss = (1-self.weight_recon) * G_loss + self.weight_recon*(recon_loss)\n",
    "            g_gradients = g_tape.gradient(total_gen_loss, self.G.trainable_variables)\n",
    "            self.g_optim.apply_gradients(zip(g_gradients, self.G.trainable_variables))\n",
    "            \n",
    "            for w in self.D.trainable_variables:\n",
    "                w.assign(tf.clip_by_value(w, -self.clip_const, self.clip_const))\n",
    "                \n",
    "            \n",
    "        return G_loss, D_loss, recon_loss\n",
    "\n",
    "\n",
    "    def make_data_generator(self, ds_train,ds_val,ds_test,embed_train,embed_val,embed_test):\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_train[...,:2],ds_train[...,2:3],embed_train))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((ds_val[...,:2],ds_val[...,2:3],embed_val))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((ds_test[...,:2],ds_test[...,2:3],embed_test))\n",
    "        train_dataset = train_dataset.shuffle(100).repeat(self.max_epochs).batch(self.batch_size)\n",
    "        val_dataset = val_dataset.batch(self.batch_size)\n",
    "        test_dataset = test_dataset.batch(self.batch_size)\n",
    "        self.train_iterator = iter(train_dataset)\n",
    "        self.val_iterator = iter(val_dataset) \n",
    "        self.test_iterator = iter(test_dataset) \n",
    "        \n",
    "    def minic_train(self,n_samples,log_freq=10):\n",
    "        \n",
    "        iterations_epoch = n_samples // self.batch_size\n",
    "        iteration = self.max_epochs * iterations_epoch\n",
    "\n",
    "        for step in range(iteration):\n",
    "            x,y  = next(self.train_iterator)\n",
    "            train_start_time = time.time()\n",
    "            time.sleep(0.1)\n",
    "            train_step_time = time.time() - train_start_time\n",
    "\n",
    "            if step % log_freq == 0:\n",
    "                template = 'training time per step: {:.5f}/s'\n",
    "                print(template.format(train_step_time))\n",
    "                print(x.shape)\n",
    "\n",
    "    def train(self,  n_samples,log_freq=5):\n",
    "    \n",
    "        iterations_epoch = n_samples // self.batch_size\n",
    "        iteration = self.max_epochs * iterations_epoch\n",
    "\n",
    "        for step in range(iteration):\n",
    "            x,y,embed = next(self.train_iterator)\n",
    "\n",
    "            train_start_time = time.time()\n",
    "\n",
    "            g_loss, d_loss, recon_loss = self.train_step(x, y,embed, step)\n",
    "            train_step_time = time.time() - train_start_time\n",
    "\n",
    "            if step % log_freq == 0:\n",
    "                template = '[{}/{}] D_loss={:.5f} G_loss={:.5f}, g_recon_loss={:.5f} training time per step: {:.5f}/s'\n",
    "                print(template.format(step, iteration, d_loss, g_loss,recon_loss, train_step_time))\n",
    "\n",
    "                \n",
    "    # def prediction(self):\n",
    "    #     iterations = self.val_samples // self.batch_size\n",
    "    #     (x_val,y_val) = next(self.val_iterator)\n",
    "    #     is_first = True\n",
    "    #     for i in range(iterations):\n",
    "    #         output = modelCase.G(x_val)\n",
    "    #         if is_first:\n",
    "    #             outputs = output\n",
    "    #             is_first = False\n",
    "    #         else:\n",
    "    #             outputs = np.concatenate((outputs,output), axis=0)\n",
    "    #     print(\"Inference is done\")\n",
    "    #     return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_shape = [n_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCase = WGANModel(mode=\"train\", hparams_dict=hparams_dict,\n",
    "                      input_shape=input_shape, target_shape=target_shape, embed_shape=embed_shape,\n",
    "                      discriminator=discriminator, generator=generator)\n",
    "\n",
    "modelCase.make_data_generator(ds_train, ds_val, ds_test,embed_train,embed_val,embed_test)\n",
    "modelCase.train(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-horizontal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-filing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.0",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
