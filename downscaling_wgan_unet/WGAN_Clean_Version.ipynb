{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c93bb-d57c-4edf-950d-2d1e31eb6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import climetlab as cml\n",
    "import os\n",
    "!pip install climetlab climetlab_maelstrom_downscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bc12c4-abf4-42fe-931c-281c2dcdae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 22:04:04.195110: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_25189/221254215.py:9: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (Input, Concatenate,Conv3D,LeakyReLU, Dense, Conv2D,Activation, BatchNormalization,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import sigmoid, linear\n",
    "from tensorflow.keras.preprocessing.image import NumpyArrayIterator\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.ops.numpy_ops.np_config as np_config\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "np_config.enable_numpy_behavior()\n",
    "import time\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from typing import Protocol\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6c339-ebfd-410c-921b-637574c8fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmlds_train = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"training\")\n",
    "cmlds_val = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"validation\")\n",
    "cmlds_test = cml.load_dataset(\"maelstrom-downscaling\", dataset=\"testing\")\n",
    "ds_train.to_netcdf(\"ds_train.nc\")\n",
    "ds_val.to_netcdf(\"ds_val.nc\")\n",
    "ds_test.to_netcdf(\"ds_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a871dd91-d841-4dc2-864d-5831b594285e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmlds_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25189/3079630106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmlds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_datelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmlds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmlds_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmlds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmlds_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(cmlds_train.all_datelist)\n",
    "ds_train = cmlds_train.to_xarray()\n",
    "ds_val = cmlds_val.to_xarray()\n",
    "ds_test = cmlds_test.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76df2f8a-21b6-42ac-bc23-9002a202cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds_train = xr.open_dataset(\"ds_train.nc\")\n",
    "ds_val = xr.open_dataset(\"ds_val.nc\")\n",
    "ds_test = xr.open_dataset(\"ds_test.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e476097-aa61-4fa3-a0d9-77fe3d78c2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efeb81bf-d51f-404d-8df6-0489b92ebf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reshape_ds(ds):\n",
    "    ds = ds.to_array(dim = \"variables\").squeeze()\n",
    "    ds = np.squeeze(ds.values)\n",
    "    ds = np.transpose(ds, (1, 2, 3, 0))\n",
    "    return ds\n",
    "ds_test = reshape_ds(ds_test)\n",
    "ds_val = reshape_ds(ds_val)\n",
    "ds_train = reshape_ds(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ffe543-0863-4401-9866-28d697ac85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = ds_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc3b212-f8f2-470c-9f7c-754898e2ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b347b-0e87-4379-9c8a-f68a113c06f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f100a1-cd63-4b5f-b863-e9f8275f4c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1464, 96, 128, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210ffdd1-142f-415d-8a18-35dc8776c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [ds_train.shape[1],ds_train.shape[2], 2]\n",
    "target_shape = [ds_train.shape[1],ds_train.shape[2],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22a3be8b-e439-4809-81e2-7e5eff8cfa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 128, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd7cfc1-5adb-4127-98f5-b48cc40841a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxiliary functions used for parsing the hyerparameters from hparams_dict\n",
    "def reduce_dict(dict_in: dict, dict_ref: dict):\n",
    "    \"\"\"\n",
    "    Reduces input dictionary to keys from reference dictionary. If the input dictionary lacks some keys, these are \n",
    "    copied over from the reference dictionary, i.e. the reference dictionary provides the defaults\n",
    "    :param dict_in: input dictionary\n",
    "    :param dict_ref: reference dictionary\n",
    "    :return: reduced form of input dictionary (with keys complemented from dict_ref if necessary)\n",
    "    \"\"\"\n",
    "    method = reduce_dict.__name__\n",
    "\n",
    "    # sanity checks\n",
    "    assert isinstance(dict_in, dict), \"%{0}: dict_in must be a dictionary, but is of type {1}\"\\\n",
    "                                      .format(method, type(dict_in))\n",
    "    assert isinstance(dict_ref, dict), \"%{0}: dict_ref must be a dictionary, but is of type {1}\"\\\n",
    "                                       .format(method, type(dict_ref)) \n",
    "\n",
    "    dict_merged = {**dict_ref, **dict_in}\n",
    "    dict_reduced = {key: dict_merged[key] for key in dict_ref}\n",
    "\n",
    "    return dict_reduced\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "532f4b61-89cd-4576-861b-a35c903963e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(inputs: tf.Tensor = None, num_filters: int = None, kernel: tuple = (3,3), padding: str=\"same\",\n",
    "              activation: str = \"relu\", kernel_init: str = \"he_normal\", l_batch_normalization: bool=False): \n",
    "\n",
    "    \"\"\"\n",
    "    A convolutional layer with optional batch normalization\n",
    "    :param inputs: the input data with dimensions nx, ny and nc\n",
    "    :param num_filters: number of filters (output channel dimension)\n",
    "    :param kernel: tuple indictating kernel size\n",
    "    :param padding: technique for padding (e.g. \"same\" or \"valid\")\n",
    "    :param activation: activation fuction for neurons (e.g. \"relu\")\n",
    "    :param kernel_init: initialization technique (e.g. \"he_normal\" or \"glorot_uniform\")\n",
    "    \"\"\"\n",
    "    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)\n",
    "    if l_batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding=\"same\", activation=\"relu\", \n",
    "                     kernel_init=\"he_normal\", l_batch_normalization=False):\n",
    "    \"\"\"\n",
    "    Sequential application of two convolutional layers (using conv_block).\n",
    "    \"\"\"\n",
    "\n",
    "    x = conv_block(inputs, num_filters, kernel, padding, activation,\n",
    "                   kernel_init, l_batch_normalization)\n",
    "    \n",
    "    for i in np.arange(n-1):\n",
    "        x = conv_block(x, num_filters, kernel, padding, activation,\n",
    "                       kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, num_filters, kernel_maxpool: tuple=(2,2), l_large: bool=False):\n",
    "    \"\"\"\n",
    "    One complete encoder-block used in U-net\n",
    "    \"\"\"\n",
    "    if l_large:\n",
    "        x = conv_block_n(inputs, num_filters, n=2)\n",
    "    else:\n",
    "        x = conv_block(inputs, num_filters)\n",
    "\n",
    "    p = MaxPool2D(kernel_maxpool)(x)\n",
    "\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= \"same\",\n",
    "                  activation: str=\"relu\", kernel_init: str=\"he_normal\", l_batch_normalization: bool=False):\n",
    "    \"\"\"\n",
    "    One complete decoder block used in U-net (reverting the encoder)\n",
    "    \"\"\"\n",
    "\n",
    "    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)\n",
    "    return x\n",
    "\n",
    "def generator(input_shape, channels_start=56, z_branch=False):\n",
    "    \"\"\"\n",
    "    Function to build up the generator architecture, here we take UNET as generator\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    \"\"\" encoder \"\"\"\n",
    "    s1, e1 = encoder_block(inputs, channels_start, l_large=True)\n",
    "    s2, e2 = encoder_block(e1, channels_start*2, l_large=False)\n",
    "    s3, e3 = encoder_block(e2, channels_start*4, l_large=False)\n",
    "\n",
    "    \"\"\" bridge encoder <-> decoder \"\"\"\n",
    "    b1 = conv_block(e3, channels_start*8)\n",
    "\n",
    "    \"\"\" decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, channels_start*4)\n",
    "    d2 = decoder_block(d1, s2, channels_start*2)\n",
    "    d3 = decoder_block(d2, s1, channels_start)\n",
    "\n",
    "    output_temp = Conv2D(1, (1,1), kernel_initializer=\"he_normal\", name=\"output_temp\")(d3)\n",
    "    if z_branch:\n",
    "        output_z = Conv2D(1, (1, 1), kernel_initializer=\"he_normal\", name=\"output_z\")(d3)\n",
    "\n",
    "        model = Model(inputs, [output_temp, output_z], name=\"t2m_downscaling_unet_with_z\")\n",
    "    else:    \n",
    "        model = Model(inputs, output_temp, name=\"t2m_downscaling_unet\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c563d867-2965-4d24-947d-b78f1b784e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(target_shape):\n",
    "    \"\"\"\n",
    "    Discriminator: this discriminator so far perfoms best on the precipitation dataset\n",
    "    \"\"\"\n",
    "\n",
    "    x = Input(target_shape)\n",
    "    conv1 = Conv2D(filters=4, kernel_size=2, strides=(1, 1), padding='same')(x)\n",
    "   \n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    conv2 = tf.reshape(conv1, [-1,1])\n",
    "    fc2 = LeakyReLU(0.2)(conv2)\n",
    "    out_logit = Dense(1)(fc2)\n",
    "    out = tf.nn.sigmoid(out_logit) \n",
    "    D = Model(x, out)\n",
    "    return D\n",
    "\n",
    "def ciritic(target_shape):\n",
    "    print(\"You are trainaing Wasserstain GAN\")\n",
    "    x = Input(target_shape)\n",
    "    conv1 = Conv3D(filters=4, kernel_size=2, strides=(1, 1,1), padding='same')(x)\n",
    "    conv1 = Activation(\"relu\")(conv1)\n",
    "    conv2 = tf.reshape(conv1, [-1,1])\n",
    "    fc2 = LeakyReLU(0.2)(conv2)\n",
    "    out = Dense(1, activiation=\"linear\")(fc2)\n",
    "    D = Model(x, out)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adac712e-4538-405b-bc46-e69cca5509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This chunk defines the losses\n",
    "from typing import Any, Callable\n",
    "### Vanilla GAN loss        \n",
    "def gan_gen_loss(D_fake):\n",
    "    \"\"\"\n",
    "    Define generator loss\n",
    "\n",
    "    Return:  the loss of generator given inputs\n",
    "    \"\"\"\n",
    "    real_labels = tf.ones_like(D_fake)\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake, labels=real_labels))            \n",
    "    return G_loss\n",
    "\n",
    "\n",
    "def gan_disc_loss(D_real, D_fake):\n",
    "    \"\"\"\n",
    "    Return the loss of discriminator (Vanilla GAN)\n",
    "    \"\"\"\n",
    "    real_labels = tf.ones_like(D_real)\n",
    "    gen_labels = tf.zeros_like(D_fake)\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real,\n",
    "                                                                          labels=real_labels))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake,\n",
    "                                                                          labels=gen_labels))\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    return D_loss\n",
    "\n",
    "def get_gan_loss(D_real, D_fake):\n",
    "    D_loss = gan_disc_loss(D_real, D_fake)\n",
    "    G_loss = gan_gen_loss(D_fake)\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "####WGAN loss\n",
    "def wgan_gen_loss(D_fake):\n",
    "    G_loss = -tf.reduce_mean(D_fake)\n",
    "    return G_loss\n",
    "\n",
    "def wgan_critic_loss(D_real,D_fake):\n",
    "    \"\"\"\n",
    "    Return the loss of critic (WGAN)\n",
    "    \"\"\"\n",
    "    D_loss = tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "    return D_loss\n",
    "\n",
    "def get_wgan_losses(D_real, D_fake):\n",
    "    G_loss =  wgan_gen_loss(D_fake)\n",
    "    D_loss = wgan_critic_loss(D_real,D_fake)\n",
    "    return D_loss, G_loss\n",
    "\n",
    "## Reconstruction loss for generator (UNet)\n",
    "def get_recon_loss(target, gen_images):\n",
    "    \"\"\"\n",
    "    Get reconstruction loss \n",
    "    \"\"\"\n",
    "    recon_loss = tf.reduce_mean(tf.square(target - gen_images))\n",
    "    return recon_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22e40ccc-1dc6-4a6c-8fa6-d77de3df2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your hparameters in a dictionary\n",
    "hparams_dict = {\n",
    "    \"batch_size\": 4,\n",
    "    \"lr\": 0.001,\n",
    "    \"max_epochs\": 5,\n",
    "    \"context_frames\": 7,\n",
    "    \"sequence_length\": 15,\n",
    "    \"ngf\": 16,\n",
    "    \"enable_gan\": True, #enable gan\n",
    "    \"enable_wgan\":True, #enable wgan \n",
    "    \"enable_cgan\":False,  #enable the conditional information \n",
    "    \"g_per_d\": 3, # How many times of discriminator are trained for training on one step generator (default 3:1)\n",
    "    \"alpha\":0.00005, #WGAN hparams\n",
    "    \"c\":0.01, #WGAN hparams\n",
    "    \"m\":64 ##WGAN hparams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0fbfa586-03d6-4f13-874f-698658616a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANModel(object):\n",
    "\n",
    "    def __init__(self, mode: str = \"train\", hparams_dict: dict = None, \n",
    "                 target_shape:list=None, input_shape:list=None,\n",
    "                 discriminator: Callable=None, generator:Callable=None): \n",
    "        \"\"\"\n",
    "         This is a class for building convLSTM GAN architecture by using updated hparameters\n",
    "             mode                  : string, either \"train\" or \"val\" \n",
    "             hparams_dict          : dictionary, contains the hyperparameters names and default values\n",
    "             input_shape           : tf.Tensor shape equal to the input shape\n",
    "        \"\"\"\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        self.target_shape = target_shape\n",
    "        #obtain the hyperparmeters\n",
    "        self.hparams_dict = hparams_dict\n",
    "        self.hparams = self.parse_hparams()\n",
    "        self.batch_size = self.hparams.batch_size\n",
    "        self.learning_rate = self.hparams.lr\n",
    "        self.max_epochs = self.hparams.max_epochs\n",
    "        self.sequence_length = self.hparams.sequence_length\n",
    "        self.context_frames = self.hparams.context_frames\n",
    "        self.loss_fun = self.hparams.loss_fun\n",
    "        self.enable_gan = self.hparams.enable_gan\n",
    "        self.enable_wgan = self.hparams.enable_wgan\n",
    "        self.enable_cgan = self.hparams.enable_cgan\n",
    "        self.g_per_d = self.hparams.g_per_d\n",
    "        self.ngf = self.hparams.ngf #latent dim\n",
    "        #Class attributes\n",
    "        self.recon_loss = None\n",
    "        self.G_loss = None\n",
    "        self.D_loss = None\n",
    "\n",
    "        \n",
    "\n",
    "    def hparams_check(self):\n",
    "        if not self.enable_gan:\n",
    "            if self.enable_wgan:\n",
    "                raise(\"You must set enable_gan to 'True' in hparams_dict congifuration\")\n",
    "\n",
    "                \n",
    "    def parse_hparams(self): \n",
    "        self.hparams_dict = dotdict(self.hparams_dict)\n",
    "        return self.hparams_dict\n",
    "    \n",
    "        \n",
    "    def define_optimizers(self):\n",
    "        self.d_optim = tf.keras.optimizers.Adam(self.learning_rate)\n",
    "        self.g_optim = tf.keras.optimizers.Adam(self.learning_rate)\n",
    "        \n",
    "    def get_losses(self, D_real, D_fake, target, gen_image):\n",
    "        \"\"\"\n",
    "        Get the losses based on the adopted model (GAN, WGAN, or UNet)\n",
    "        \"\"\"\n",
    "        # Reconstruction loss\n",
    "        recon_loss = get_recon_loss(target,gen_image)\n",
    "        \n",
    "        if self.enable_wgan:\n",
    "            G_loss, D_loss = get_wgan_losses(D_real, D_fake)\n",
    "        else:\n",
    "            #vanilla GAN\n",
    "             G_loss, D_loss = get_gan_losses(D_real, D_fake)\n",
    "                \n",
    "        return G_loss, D_loss, recon_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, target, i, g_per_d):\n",
    "        \"\"\"\n",
    "        Training models\n",
    "        i: The training stepe\n",
    "        \"\"\"\n",
    "    \n",
    "        self.G = self.generator(self.input_shape)\n",
    "        self.D = self.discriminator(self.target_shape)\n",
    "        self.define_optimizers()\n",
    "        with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
    "\n",
    "            gen_images = self.G(inputs)\n",
    "            \n",
    "            self.D_real = self.D(target)\n",
    "            self.D_fake = self.D(gen_images) \n",
    "\n",
    "            G_loss, D_loss, recon_loss = self.get_losses(self.D_real, self.D_fake, target, gen_images)\n",
    "            \n",
    "            d_gradients = d_tape.gradient(D_loss, self.D.trainable_variables)\n",
    "\n",
    "            if not self.enable_gan:\n",
    "                if i == 0:\n",
    "                    print(\"Train only on generator\")\n",
    "                # if the discriminator is not used for training, only train generator part\n",
    "                g_gradients = g_tape.gradient(recon_loss, self.G.trainable_variables)\n",
    "                self.g_optim.apply_gradients(zip(g_gradients, self.G.trainable_variables))\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    if self.enable_wgan:\n",
    "                        print(\"You are training both generator and critic (WGAN)\")\n",
    "                    else:\n",
    "                        print(\"You are training both generator and discriminator (GAN)\")\n",
    "                        \n",
    "                    print(\"You are training {} times generator per one time descriminator\".format(g_per_d))\n",
    "                \n",
    "                #define the training stratigy (ratio of number iteration of training on generator and discriminator)\n",
    "                if i%g_per_d == 0:                  \n",
    "                    self.d_optim.apply_gradients(zip(d_gradients, self.D.trainable_variables))\n",
    "                \n",
    "                g_gradients = g_tape.gradient(G_loss + recon_loss, self.G.trainable_variables)\n",
    "                self.g_optim.apply_gradients(zip(g_gradients, self.G.trainable_variables))\n",
    "\n",
    "        return G_loss, D_loss, recon_loss\n",
    "\n",
    "    \n",
    "    def make_data_generator(self, ds_train,ds_val,ds_test):\n",
    "        \n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_train[...,:2],ds_train[...,2:3]))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((ds_val[...,:2],ds_val[...,2:3]))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((ds_test[...,:2],ds_test[...,2:3]))\n",
    "        train_dataset = train_dataset.shuffle(100).repeat(self.max_epochs).batch(self.batch_size)\n",
    "        val_dataset = val_dataset.batch(self.batch_size)\n",
    "        test_dataset = test_dataset.batch(self.batch_size)\n",
    "        self.train_iterator = iter(train_dataset)\n",
    "        self.val_iterator = iter(val_dataset) \n",
    "        self.test_iterator = iter(test_dataset) \n",
    "        \n",
    "    def minic_train(self,n_samples,log_freq=10):\n",
    "        \n",
    "        iterations_epoch = n_samples // self.batch_size\n",
    "        iteration = self.max_epochs * iterations_epoch\n",
    "\n",
    "        for step in range(iteration):\n",
    "            x,y  = next(self.train_iterator)\n",
    "            train_start_time = time.time()\n",
    "            time.sleep(0.1)\n",
    "            train_step_time = time.time() - train_start_time\n",
    "\n",
    "            if step % log_freq == 0:\n",
    "                template = 'training time per step: {:.5f}/s'\n",
    "                print(template.format(train_step_time))\n",
    "                print(x.shape)\n",
    "\n",
    "\n",
    "    def train(self,  n_samples,log_freq=5):\n",
    "    \n",
    "        iterations_epoch = n_samples // self.batch_size\n",
    "        iteration = self.max_epochs * iterations_epoch\n",
    "\n",
    "        for step in range(iteration):\n",
    "            x,y = next(self.train_iterator)\n",
    "\n",
    "            train_start_time = time.time()\n",
    "        \n",
    "            g_loss, d_loss, recon_loss = self.train_step(x, y, step, self.g_per_d)\n",
    "            train_step_time = time.time() - train_start_time\n",
    "\n",
    "            if step % log_freq == 0:\n",
    "                template = '[{}/{}] D_loss={:.5f} G_loss={:.5f}, g_recon_loss={:.5f} training time per step: {:.5f}/s'\n",
    "                print(template.format(step, iteration, d_loss, g_loss,recon_loss, train_step_time))\n",
    "\n",
    "                \n",
    "    # def prediction(self):\n",
    "    #     iterations = self.val_samples // self.batch_size\n",
    "    #     (x_val,y_val) = next(self.val_iterator)\n",
    "    #     is_first = True\n",
    "    #     for i in range(iterations):\n",
    "    #         output = modelCase.G(x_val)\n",
    "    #         if is_first:\n",
    "    #             outputs = output\n",
    "    #             is_first = False\n",
    "    #         else:\n",
    "    #             outputs = np.concatenate((outputs,output), axis=0)\n",
    "    #     print(\"Inference is done\")\n",
    "    #     return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0c5d3-4c7e-4a73-9096-b8faed38481a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21beac37-707e-45a4-b41e-ec4e049ababd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da4019-178e-4f1d-94d7-f4b4b3595eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ac1fa-bc54-4b69-a1e8-56d6b2cf5458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are training both generator and critic (WGAN)\n",
      "You are training 3 times generator per one time descriminator\n",
      "[0/1830] D_loss=-0.81811 G_loss=-0.00843, g_recon_loss=9594499.31788 training time per step: 0.52418/s\n",
      "[5/1830] D_loss=-0.74646 G_loss=-0.00597, g_recon_loss=4640639.40801 training time per step: 0.47510/s\n",
      "[10/1830] D_loss=-0.74583 G_loss=-0.02166, g_recon_loss=73244644.45573 training time per step: 0.57602/s\n",
      "[15/1830] D_loss=-0.76984 G_loss=0.03565, g_recon_loss=36539643.50363 training time per step: 0.51215/s\n",
      "[20/1830] D_loss=-0.68080 G_loss=-0.02664, g_recon_loss=9068457.96499 training time per step: 0.52651/s\n",
      "[25/1830] D_loss=-0.67350 G_loss=-0.03882, g_recon_loss=27793849.95770 training time per step: 0.47971/s\n",
      "[30/1830] D_loss=-0.81420 G_loss=-0.17946, g_recon_loss=77612506.73370 training time per step: 0.82808/s\n",
      "[35/1830] D_loss=-0.31193 G_loss=0.05206, g_recon_loss=15611209.11627 training time per step: 0.50483/s\n",
      "[40/1830] D_loss=-0.35653 G_loss=-0.21204, g_recon_loss=69567392.09095 training time per step: 0.56376/s\n",
      "[45/1830] D_loss=-0.48188 G_loss=-0.02350, g_recon_loss=4011317.98796 training time per step: 0.55768/s\n",
      "[50/1830] D_loss=-0.69323 G_loss=-0.05587, g_recon_loss=19300026.88571 training time per step: 0.52627/s\n",
      "[55/1830] D_loss=-0.84662 G_loss=0.00697, g_recon_loss=18499098.91211 training time per step: 0.49236/s\n",
      "[60/1830] D_loss=-0.22790 G_loss=0.00734, g_recon_loss=31043464.10873 training time per step: 0.47438/s\n",
      "[65/1830] D_loss=-0.76925 G_loss=-0.02321, g_recon_loss=23190870.23918 training time per step: 0.47971/s\n",
      "[70/1830] D_loss=-0.73269 G_loss=0.10880, g_recon_loss=77384352.88275 training time per step: 0.53401/s\n",
      "[75/1830] D_loss=-0.74930 G_loss=-0.01096, g_recon_loss=12560044.68550 training time per step: 0.55637/s\n"
     ]
    }
   ],
   "source": [
    "modelCase = WGANModel(mode=\"train\", hparams_dict=hparams_dict,\n",
    "                      input_shape=input_shape,target_shape=target_shape,\n",
    "                      discriminator=discriminator, generator=generator)\n",
    "\n",
    "modelCase.make_data_generator(ds_train, ds_val, ds_test)\n",
    "modelCase.train(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b15e2-55f1-4dec-aa64-7c8425b278b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e6d98-1b1b-4bd0-add2-654179383ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b68c6-8792-4877-bf99-e2587bc995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391db88-1622-47b9-846f-96ad5cf361b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.1",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
